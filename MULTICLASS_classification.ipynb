{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MULTICLASS_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwQCoA/5edOTBTf+c0b6pY"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjDZqn1BFBP"
      },
      "source": [
        "\n",
        "\n",
        "**Importing libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXgbzyFYAlav"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vb9-l5IBRah"
      },
      "source": [
        "**Importing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5voQddgVFCgm",
        "outputId": "6e24cec2-c102-41ad-b057-e1330b148e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "data = pd.read_csv('iris.csv',parse_dates=True) \n",
        "data.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>6.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
              "63            6.1          2.9           4.7          1.4  Versicolor\n",
              "138           6.0          3.0           4.8          1.8   Virginica\n",
              "71            6.1          2.8           4.0          1.3  Versicolor\n",
              "127           6.1          3.0           4.9          1.8   Virginica\n",
              "17            5.1          3.5           1.4          0.3      Setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6n6-iKYGmQP"
      },
      "source": [
        "**Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HED8GZjqGlrv",
        "outputId": "af667c58-f5bb-4935-9d47-8cfc7beacbe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.isna().sum() #Checking for missing values"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal.length    0\n",
              "sepal.width     0\n",
              "petal.length    0\n",
              "petal.width     0\n",
              "variety         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfvwFsSCF4ib",
        "outputId": "a492a41c-f0ef-4f69-b67a-628e73d9921a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dszaHogZgkgS",
        "outputId": "020aaec8-9f07-4f0a-a2dc-26c3e1ba54da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.variety.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Versicolor    50\n",
              "Virginica     50\n",
              "Setosa        50\n",
              "Name: variety, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxOvIe62F9Jx",
        "outputId": "18256d39-862e-45f9-eecc-53fd308de31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal.length  sepal.width  petal.length  petal.width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.057333      3.758000     1.199333\n",
              "std        0.828066     0.435866      1.765298     0.762238\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXcNxiqGHwnp"
      },
      "source": [
        "For better performance of our model we need to keep numerical values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM1WKP8UHgEE",
        "outputId": "142a853b-df1a-4076-86cd-b353c25744dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.max() #displays the max of every column"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal.length          7.9\n",
              "sepal.width           4.4\n",
              "petal.length          6.9\n",
              "petal.width           2.5\n",
              "variety         Virginica\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F09rU5YBH8OW"
      },
      "source": [
        "data['sepal.length'] = data['sepal.length']/7.9\n",
        "data['sepal.width'] = data['sepal.width']/4.4\n",
        "data['petal.length'] = data['petal.length']/6.9\n",
        "data['petal.width'] = data['petal.width']/2.5\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmsbuarTJ-kx",
        "outputId": "dd927a79-528d-40b3-a303-8b4616b83e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.936709</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.884058</td>\n",
              "      <td>0.76</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.911392</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.884058</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>0.784810</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.72</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.835443</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.637681</td>\n",
              "      <td>0.56</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.683544</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.08</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
              "130      0.936709     0.636364      0.884058         0.76   Virginica\n",
              "109      0.911392     0.818182      0.884058         1.00   Virginica\n",
              "126      0.784810     0.636364      0.695652         0.72   Virginica\n",
              "75       0.835443     0.681818      0.637681         0.56  Versicolor\n",
              "10       0.683544     0.840909      0.217391         0.08      Setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kovNhYdPafQ8"
      },
      "source": [
        "**Model creation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9WSecMOoOVl"
      },
      "source": [
        "data = data.values\n",
        "X = data[:,0:4].astype(float)\n",
        "Y = data[:,4]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysN0AIRvoy6f",
        "outputId": "fedf024e-4d35-4aec-a9e4-3df03e181529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.64556962, 0.79545455, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.68181818, 0.20289855, 0.08      ],\n",
              "       [0.59493671, 0.72727273, 0.1884058 , 0.08      ],\n",
              "       [0.58227848, 0.70454545, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.81818182, 0.20289855, 0.08      ],\n",
              "       [0.6835443 , 0.88636364, 0.24637681, 0.16      ],\n",
              "       [0.58227848, 0.77272727, 0.20289855, 0.12      ],\n",
              "       [0.63291139, 0.77272727, 0.2173913 , 0.08      ],\n",
              "       [0.55696203, 0.65909091, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.70454545, 0.2173913 , 0.04      ],\n",
              "       [0.6835443 , 0.84090909, 0.2173913 , 0.08      ],\n",
              "       [0.60759494, 0.77272727, 0.23188406, 0.08      ],\n",
              "       [0.60759494, 0.68181818, 0.20289855, 0.04      ],\n",
              "       [0.5443038 , 0.68181818, 0.15942029, 0.04      ],\n",
              "       [0.73417722, 0.90909091, 0.17391304, 0.08      ],\n",
              "       [0.72151899, 1.        , 0.2173913 , 0.16      ],\n",
              "       [0.6835443 , 0.88636364, 0.1884058 , 0.16      ],\n",
              "       [0.64556962, 0.79545455, 0.20289855, 0.12      ],\n",
              "       [0.72151899, 0.86363636, 0.24637681, 0.12      ],\n",
              "       [0.64556962, 0.86363636, 0.2173913 , 0.12      ],\n",
              "       [0.6835443 , 0.77272727, 0.24637681, 0.08      ],\n",
              "       [0.64556962, 0.84090909, 0.2173913 , 0.16      ],\n",
              "       [0.58227848, 0.81818182, 0.14492754, 0.08      ],\n",
              "       [0.64556962, 0.75      , 0.24637681, 0.2       ],\n",
              "       [0.60759494, 0.77272727, 0.27536232, 0.08      ],\n",
              "       [0.63291139, 0.68181818, 0.23188406, 0.08      ],\n",
              "       [0.63291139, 0.77272727, 0.23188406, 0.16      ],\n",
              "       [0.65822785, 0.79545455, 0.2173913 , 0.08      ],\n",
              "       [0.65822785, 0.77272727, 0.20289855, 0.08      ],\n",
              "       [0.59493671, 0.72727273, 0.23188406, 0.08      ],\n",
              "       [0.60759494, 0.70454545, 0.23188406, 0.08      ],\n",
              "       [0.6835443 , 0.77272727, 0.2173913 , 0.16      ],\n",
              "       [0.65822785, 0.93181818, 0.2173913 , 0.04      ],\n",
              "       [0.69620253, 0.95454545, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.70454545, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.72727273, 0.17391304, 0.08      ],\n",
              "       [0.69620253, 0.79545455, 0.1884058 , 0.08      ],\n",
              "       [0.62025316, 0.81818182, 0.20289855, 0.04      ],\n",
              "       [0.55696203, 0.68181818, 0.1884058 , 0.08      ],\n",
              "       [0.64556962, 0.77272727, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.79545455, 0.1884058 , 0.12      ],\n",
              "       [0.56962025, 0.52272727, 0.1884058 , 0.12      ],\n",
              "       [0.55696203, 0.72727273, 0.1884058 , 0.08      ],\n",
              "       [0.63291139, 0.79545455, 0.23188406, 0.24      ],\n",
              "       [0.64556962, 0.86363636, 0.27536232, 0.16      ],\n",
              "       [0.60759494, 0.68181818, 0.20289855, 0.12      ],\n",
              "       [0.64556962, 0.86363636, 0.23188406, 0.08      ],\n",
              "       [0.58227848, 0.72727273, 0.20289855, 0.08      ],\n",
              "       [0.67088608, 0.84090909, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.75      , 0.20289855, 0.08      ],\n",
              "       [0.88607595, 0.72727273, 0.68115942, 0.56      ],\n",
              "       [0.81012658, 0.72727273, 0.65217391, 0.6       ],\n",
              "       [0.87341772, 0.70454545, 0.71014493, 0.6       ],\n",
              "       [0.69620253, 0.52272727, 0.57971014, 0.52      ],\n",
              "       [0.82278481, 0.63636364, 0.66666667, 0.6       ],\n",
              "       [0.72151899, 0.63636364, 0.65217391, 0.52      ],\n",
              "       [0.79746835, 0.75      , 0.68115942, 0.64      ],\n",
              "       [0.62025316, 0.54545455, 0.47826087, 0.4       ],\n",
              "       [0.83544304, 0.65909091, 0.66666667, 0.52      ],\n",
              "       [0.65822785, 0.61363636, 0.56521739, 0.56      ],\n",
              "       [0.63291139, 0.45454545, 0.50724638, 0.4       ],\n",
              "       [0.74683544, 0.68181818, 0.60869565, 0.6       ],\n",
              "       [0.75949367, 0.5       , 0.57971014, 0.4       ],\n",
              "       [0.7721519 , 0.65909091, 0.68115942, 0.56      ],\n",
              "       [0.70886076, 0.65909091, 0.52173913, 0.52      ],\n",
              "       [0.84810127, 0.70454545, 0.63768116, 0.56      ],\n",
              "       [0.70886076, 0.68181818, 0.65217391, 0.6       ],\n",
              "       [0.73417722, 0.61363636, 0.5942029 , 0.4       ],\n",
              "       [0.78481013, 0.5       , 0.65217391, 0.6       ],\n",
              "       [0.70886076, 0.56818182, 0.56521739, 0.44      ],\n",
              "       [0.74683544, 0.72727273, 0.69565217, 0.72      ],\n",
              "       [0.7721519 , 0.63636364, 0.57971014, 0.52      ],\n",
              "       [0.79746835, 0.56818182, 0.71014493, 0.6       ],\n",
              "       [0.7721519 , 0.63636364, 0.68115942, 0.48      ],\n",
              "       [0.81012658, 0.65909091, 0.62318841, 0.52      ],\n",
              "       [0.83544304, 0.68181818, 0.63768116, 0.56      ],\n",
              "       [0.86075949, 0.63636364, 0.69565217, 0.56      ],\n",
              "       [0.84810127, 0.68181818, 0.72463768, 0.68      ],\n",
              "       [0.75949367, 0.65909091, 0.65217391, 0.6       ],\n",
              "       [0.72151899, 0.59090909, 0.50724638, 0.4       ],\n",
              "       [0.69620253, 0.54545455, 0.55072464, 0.44      ],\n",
              "       [0.69620253, 0.54545455, 0.53623188, 0.4       ],\n",
              "       [0.73417722, 0.61363636, 0.56521739, 0.48      ],\n",
              "       [0.75949367, 0.61363636, 0.73913043, 0.64      ],\n",
              "       [0.6835443 , 0.68181818, 0.65217391, 0.6       ],\n",
              "       [0.75949367, 0.77272727, 0.65217391, 0.64      ],\n",
              "       [0.84810127, 0.70454545, 0.68115942, 0.6       ],\n",
              "       [0.79746835, 0.52272727, 0.63768116, 0.52      ],\n",
              "       [0.70886076, 0.68181818, 0.5942029 , 0.52      ],\n",
              "       [0.69620253, 0.56818182, 0.57971014, 0.52      ],\n",
              "       [0.69620253, 0.59090909, 0.63768116, 0.48      ],\n",
              "       [0.7721519 , 0.68181818, 0.66666667, 0.56      ],\n",
              "       [0.73417722, 0.59090909, 0.57971014, 0.48      ],\n",
              "       [0.63291139, 0.52272727, 0.47826087, 0.4       ],\n",
              "       [0.70886076, 0.61363636, 0.60869565, 0.52      ],\n",
              "       [0.72151899, 0.68181818, 0.60869565, 0.48      ],\n",
              "       [0.72151899, 0.65909091, 0.60869565, 0.52      ],\n",
              "       [0.78481013, 0.65909091, 0.62318841, 0.52      ],\n",
              "       [0.64556962, 0.56818182, 0.43478261, 0.44      ],\n",
              "       [0.72151899, 0.63636364, 0.5942029 , 0.52      ],\n",
              "       [0.79746835, 0.75      , 0.86956522, 1.        ],\n",
              "       [0.73417722, 0.61363636, 0.73913043, 0.76      ],\n",
              "       [0.89873418, 0.68181818, 0.85507246, 0.84      ],\n",
              "       [0.79746835, 0.65909091, 0.8115942 , 0.72      ],\n",
              "       [0.82278481, 0.68181818, 0.84057971, 0.88      ],\n",
              "       [0.96202532, 0.68181818, 0.95652174, 0.84      ],\n",
              "       [0.62025316, 0.56818182, 0.65217391, 0.68      ],\n",
              "       [0.92405063, 0.65909091, 0.91304348, 0.72      ],\n",
              "       [0.84810127, 0.56818182, 0.84057971, 0.72      ],\n",
              "       [0.91139241, 0.81818182, 0.88405797, 1.        ],\n",
              "       [0.82278481, 0.72727273, 0.73913043, 0.8       ],\n",
              "       [0.81012658, 0.61363636, 0.76811594, 0.76      ],\n",
              "       [0.86075949, 0.68181818, 0.79710145, 0.84      ],\n",
              "       [0.72151899, 0.56818182, 0.72463768, 0.8       ],\n",
              "       [0.73417722, 0.63636364, 0.73913043, 0.96      ],\n",
              "       [0.81012658, 0.72727273, 0.76811594, 0.92      ],\n",
              "       [0.82278481, 0.68181818, 0.79710145, 0.72      ],\n",
              "       [0.97468354, 0.86363636, 0.97101449, 0.88      ],\n",
              "       [0.97468354, 0.59090909, 1.        , 0.92      ],\n",
              "       [0.75949367, 0.5       , 0.72463768, 0.6       ],\n",
              "       [0.87341772, 0.72727273, 0.82608696, 0.92      ],\n",
              "       [0.70886076, 0.63636364, 0.71014493, 0.8       ],\n",
              "       [0.97468354, 0.63636364, 0.97101449, 0.8       ],\n",
              "       [0.79746835, 0.61363636, 0.71014493, 0.72      ],\n",
              "       [0.84810127, 0.75      , 0.82608696, 0.84      ],\n",
              "       [0.91139241, 0.72727273, 0.86956522, 0.72      ],\n",
              "       [0.78481013, 0.63636364, 0.69565217, 0.72      ],\n",
              "       [0.7721519 , 0.68181818, 0.71014493, 0.72      ],\n",
              "       [0.81012658, 0.63636364, 0.8115942 , 0.84      ],\n",
              "       [0.91139241, 0.68181818, 0.84057971, 0.64      ],\n",
              "       [0.93670886, 0.63636364, 0.88405797, 0.76      ],\n",
              "       [1.        , 0.86363636, 0.92753623, 0.8       ],\n",
              "       [0.81012658, 0.63636364, 0.8115942 , 0.88      ],\n",
              "       [0.79746835, 0.63636364, 0.73913043, 0.6       ],\n",
              "       [0.7721519 , 0.59090909, 0.8115942 , 0.56      ],\n",
              "       [0.97468354, 0.68181818, 0.88405797, 0.92      ],\n",
              "       [0.79746835, 0.77272727, 0.8115942 , 0.96      ],\n",
              "       [0.81012658, 0.70454545, 0.79710145, 0.72      ],\n",
              "       [0.75949367, 0.68181818, 0.69565217, 0.72      ],\n",
              "       [0.87341772, 0.70454545, 0.7826087 , 0.84      ],\n",
              "       [0.84810127, 0.70454545, 0.8115942 , 0.96      ],\n",
              "       [0.87341772, 0.70454545, 0.73913043, 0.92      ],\n",
              "       [0.73417722, 0.61363636, 0.73913043, 0.76      ],\n",
              "       [0.86075949, 0.72727273, 0.85507246, 0.92      ],\n",
              "       [0.84810127, 0.75      , 0.82608696, 1.        ],\n",
              "       [0.84810127, 0.68181818, 0.75362319, 0.92      ],\n",
              "       [0.79746835, 0.56818182, 0.72463768, 0.76      ],\n",
              "       [0.82278481, 0.68181818, 0.75362319, 0.8       ],\n",
              "       [0.78481013, 0.77272727, 0.7826087 , 0.92      ],\n",
              "       [0.74683544, 0.68181818, 0.73913043, 0.72      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUyIADYUpTPF",
        "outputId": "aa85a00c-2c04-4a49-9205-478c25ca690a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFz7fGJuX67"
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables \n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6MjFXgVUgZa",
        "outputId": "b0ca93a0-cdbf-44b8-bb69-12c875af037b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dummy_y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdDgwwaDzybA"
      },
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6NGvR8Q8t-x",
        "outputId": "8554369a-5c67-4db7-f51a-ed2c1721fafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist = baseline_model().fit(X, dummy_y, batch_size=5, epochs=200, verbose=2)\n",
        "                 "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "30/30 - 0s - loss: 1.1315 - accuracy: 0.3333\n",
            "Epoch 2/200\n",
            "30/30 - 0s - loss: 1.1170 - accuracy: 0.3333\n",
            "Epoch 3/200\n",
            "30/30 - 0s - loss: 1.1031 - accuracy: 0.3333\n",
            "Epoch 4/200\n",
            "30/30 - 0s - loss: 1.0857 - accuracy: 0.4467\n",
            "Epoch 5/200\n",
            "30/30 - 0s - loss: 1.0676 - accuracy: 0.4467\n",
            "Epoch 6/200\n",
            "30/30 - 0s - loss: 1.0494 - accuracy: 0.5467\n",
            "Epoch 7/200\n",
            "30/30 - 0s - loss: 1.0294 - accuracy: 0.6000\n",
            "Epoch 8/200\n",
            "30/30 - 0s - loss: 1.0094 - accuracy: 0.6333\n",
            "Epoch 9/200\n",
            "30/30 - 0s - loss: 0.9887 - accuracy: 0.6467\n",
            "Epoch 10/200\n",
            "30/30 - 0s - loss: 0.9667 - accuracy: 0.6533\n",
            "Epoch 11/200\n",
            "30/30 - 0s - loss: 0.9437 - accuracy: 0.6533\n",
            "Epoch 12/200\n",
            "30/30 - 0s - loss: 0.9199 - accuracy: 0.6800\n",
            "Epoch 13/200\n",
            "30/30 - 0s - loss: 0.8952 - accuracy: 0.8533\n",
            "Epoch 14/200\n",
            "30/30 - 0s - loss: 0.8706 - accuracy: 0.8733\n",
            "Epoch 15/200\n",
            "30/30 - 0s - loss: 0.8453 - accuracy: 0.8133\n",
            "Epoch 16/200\n",
            "30/30 - 0s - loss: 0.8200 - accuracy: 0.8667\n",
            "Epoch 17/200\n",
            "30/30 - 0s - loss: 0.7952 - accuracy: 0.8400\n",
            "Epoch 18/200\n",
            "30/30 - 0s - loss: 0.7701 - accuracy: 0.7733\n",
            "Epoch 19/200\n",
            "30/30 - 0s - loss: 0.7462 - accuracy: 0.6867\n",
            "Epoch 20/200\n",
            "30/30 - 0s - loss: 0.7229 - accuracy: 0.7267\n",
            "Epoch 21/200\n",
            "30/30 - 0s - loss: 0.7008 - accuracy: 0.7133\n",
            "Epoch 22/200\n",
            "30/30 - 0s - loss: 0.6799 - accuracy: 0.7667\n",
            "Epoch 23/200\n",
            "30/30 - 0s - loss: 0.6614 - accuracy: 0.7200\n",
            "Epoch 24/200\n",
            "30/30 - 0s - loss: 0.6417 - accuracy: 0.7333\n",
            "Epoch 25/200\n",
            "30/30 - 0s - loss: 0.6236 - accuracy: 0.7933\n",
            "Epoch 26/200\n",
            "30/30 - 0s - loss: 0.6066 - accuracy: 0.8067\n",
            "Epoch 27/200\n",
            "30/30 - 0s - loss: 0.5909 - accuracy: 0.8067\n",
            "Epoch 28/200\n",
            "30/30 - 0s - loss: 0.5758 - accuracy: 0.8133\n",
            "Epoch 29/200\n",
            "30/30 - 0s - loss: 0.5629 - accuracy: 0.8800\n",
            "Epoch 30/200\n",
            "30/30 - 0s - loss: 0.5493 - accuracy: 0.8400\n",
            "Epoch 31/200\n",
            "30/30 - 0s - loss: 0.5354 - accuracy: 0.8467\n",
            "Epoch 32/200\n",
            "30/30 - 0s - loss: 0.5243 - accuracy: 0.8667\n",
            "Epoch 33/200\n",
            "30/30 - 0s - loss: 0.5137 - accuracy: 0.9400\n",
            "Epoch 34/200\n",
            "30/30 - 0s - loss: 0.5020 - accuracy: 0.9200\n",
            "Epoch 35/200\n",
            "30/30 - 0s - loss: 0.4913 - accuracy: 0.9267\n",
            "Epoch 36/200\n",
            "30/30 - 0s - loss: 0.4819 - accuracy: 0.9200\n",
            "Epoch 37/200\n",
            "30/30 - 0s - loss: 0.4718 - accuracy: 0.9333\n",
            "Epoch 38/200\n",
            "30/30 - 0s - loss: 0.4624 - accuracy: 0.9600\n",
            "Epoch 39/200\n",
            "30/30 - 0s - loss: 0.4538 - accuracy: 0.9600\n",
            "Epoch 40/200\n",
            "30/30 - 0s - loss: 0.4458 - accuracy: 0.9600\n",
            "Epoch 41/200\n",
            "30/30 - 0s - loss: 0.4363 - accuracy: 0.9667\n",
            "Epoch 42/200\n",
            "30/30 - 0s - loss: 0.4284 - accuracy: 0.9667\n",
            "Epoch 43/200\n",
            "30/30 - 0s - loss: 0.4224 - accuracy: 0.9533\n",
            "Epoch 44/200\n",
            "30/30 - 0s - loss: 0.4124 - accuracy: 0.9667\n",
            "Epoch 45/200\n",
            "30/30 - 0s - loss: 0.4054 - accuracy: 0.9600\n",
            "Epoch 46/200\n",
            "30/30 - 0s - loss: 0.3985 - accuracy: 0.9600\n",
            "Epoch 47/200\n",
            "30/30 - 0s - loss: 0.3943 - accuracy: 0.9533\n",
            "Epoch 48/200\n",
            "30/30 - 0s - loss: 0.3840 - accuracy: 0.9533\n",
            "Epoch 49/200\n",
            "30/30 - 0s - loss: 0.3777 - accuracy: 0.9667\n",
            "Epoch 50/200\n",
            "30/30 - 0s - loss: 0.3711 - accuracy: 0.9600\n",
            "Epoch 51/200\n",
            "30/30 - 0s - loss: 0.3650 - accuracy: 0.9533\n",
            "Epoch 52/200\n",
            "30/30 - 0s - loss: 0.3588 - accuracy: 0.9533\n",
            "Epoch 53/200\n",
            "30/30 - 0s - loss: 0.3531 - accuracy: 0.9533\n",
            "Epoch 54/200\n",
            "30/30 - 0s - loss: 0.3484 - accuracy: 0.9533\n",
            "Epoch 55/200\n",
            "30/30 - 0s - loss: 0.3417 - accuracy: 0.9533\n",
            "Epoch 56/200\n",
            "30/30 - 0s - loss: 0.3361 - accuracy: 0.9533\n",
            "Epoch 57/200\n",
            "30/30 - 0s - loss: 0.3306 - accuracy: 0.9533\n",
            "Epoch 58/200\n",
            "30/30 - 0s - loss: 0.3262 - accuracy: 0.9600\n",
            "Epoch 59/200\n",
            "30/30 - 0s - loss: 0.3208 - accuracy: 0.9533\n",
            "Epoch 60/200\n",
            "30/30 - 0s - loss: 0.3153 - accuracy: 0.9533\n",
            "Epoch 61/200\n",
            "30/30 - 0s - loss: 0.3105 - accuracy: 0.9533\n",
            "Epoch 62/200\n",
            "30/30 - 0s - loss: 0.3058 - accuracy: 0.9533\n",
            "Epoch 63/200\n",
            "30/30 - 0s - loss: 0.3006 - accuracy: 0.9533\n",
            "Epoch 64/200\n",
            "30/30 - 0s - loss: 0.2967 - accuracy: 0.9600\n",
            "Epoch 65/200\n",
            "30/30 - 0s - loss: 0.2922 - accuracy: 0.9533\n",
            "Epoch 66/200\n",
            "30/30 - 0s - loss: 0.2884 - accuracy: 0.9533\n",
            "Epoch 67/200\n",
            "30/30 - 0s - loss: 0.2834 - accuracy: 0.9533\n",
            "Epoch 68/200\n",
            "30/30 - 0s - loss: 0.2792 - accuracy: 0.9533\n",
            "Epoch 69/200\n",
            "30/30 - 0s - loss: 0.2759 - accuracy: 0.9600\n",
            "Epoch 70/200\n",
            "30/30 - 0s - loss: 0.2728 - accuracy: 0.9533\n",
            "Epoch 71/200\n",
            "30/30 - 0s - loss: 0.2685 - accuracy: 0.9600\n",
            "Epoch 72/200\n",
            "30/30 - 0s - loss: 0.2654 - accuracy: 0.9667\n",
            "Epoch 73/200\n",
            "30/30 - 0s - loss: 0.2604 - accuracy: 0.9600\n",
            "Epoch 74/200\n",
            "30/30 - 0s - loss: 0.2569 - accuracy: 0.9533\n",
            "Epoch 75/200\n",
            "30/30 - 0s - loss: 0.2526 - accuracy: 0.9533\n",
            "Epoch 76/200\n",
            "30/30 - 0s - loss: 0.2493 - accuracy: 0.9533\n",
            "Epoch 77/200\n",
            "30/30 - 0s - loss: 0.2468 - accuracy: 0.9533\n",
            "Epoch 78/200\n",
            "30/30 - 0s - loss: 0.2436 - accuracy: 0.9667\n",
            "Epoch 79/200\n",
            "30/30 - 0s - loss: 0.2396 - accuracy: 0.9533\n",
            "Epoch 80/200\n",
            "30/30 - 0s - loss: 0.2363 - accuracy: 0.9533\n",
            "Epoch 81/200\n",
            "30/30 - 0s - loss: 0.2339 - accuracy: 0.9533\n",
            "Epoch 82/200\n",
            "30/30 - 0s - loss: 0.2310 - accuracy: 0.9600\n",
            "Epoch 83/200\n",
            "30/30 - 0s - loss: 0.2292 - accuracy: 0.9533\n",
            "Epoch 84/200\n",
            "30/30 - 0s - loss: 0.2262 - accuracy: 0.9533\n",
            "Epoch 85/200\n",
            "30/30 - 0s - loss: 0.2232 - accuracy: 0.9667\n",
            "Epoch 86/200\n",
            "30/30 - 0s - loss: 0.2206 - accuracy: 0.9533\n",
            "Epoch 87/200\n",
            "30/30 - 0s - loss: 0.2162 - accuracy: 0.9600\n",
            "Epoch 88/200\n",
            "30/30 - 0s - loss: 0.2143 - accuracy: 0.9733\n",
            "Epoch 89/200\n",
            "30/30 - 0s - loss: 0.2113 - accuracy: 0.9600\n",
            "Epoch 90/200\n",
            "30/30 - 0s - loss: 0.2089 - accuracy: 0.9533\n",
            "Epoch 91/200\n",
            "30/30 - 0s - loss: 0.2069 - accuracy: 0.9533\n",
            "Epoch 92/200\n",
            "30/30 - 0s - loss: 0.2040 - accuracy: 0.9600\n",
            "Epoch 93/200\n",
            "30/30 - 0s - loss: 0.2014 - accuracy: 0.9533\n",
            "Epoch 94/200\n",
            "30/30 - 0s - loss: 0.1994 - accuracy: 0.9533\n",
            "Epoch 95/200\n",
            "30/30 - 0s - loss: 0.1971 - accuracy: 0.9600\n",
            "Epoch 96/200\n",
            "30/30 - 0s - loss: 0.1948 - accuracy: 0.9533\n",
            "Epoch 97/200\n",
            "30/30 - 0s - loss: 0.1929 - accuracy: 0.9533\n",
            "Epoch 98/200\n",
            "30/30 - 0s - loss: 0.1903 - accuracy: 0.9533\n",
            "Epoch 99/200\n",
            "30/30 - 0s - loss: 0.1885 - accuracy: 0.9667\n",
            "Epoch 100/200\n",
            "30/30 - 0s - loss: 0.1867 - accuracy: 0.9600\n",
            "Epoch 101/200\n",
            "30/30 - 0s - loss: 0.1849 - accuracy: 0.9533\n",
            "Epoch 102/200\n",
            "30/30 - 0s - loss: 0.1836 - accuracy: 0.9600\n",
            "Epoch 103/200\n",
            "30/30 - 0s - loss: 0.1808 - accuracy: 0.9667\n",
            "Epoch 104/200\n",
            "30/30 - 0s - loss: 0.1791 - accuracy: 0.9533\n",
            "Epoch 105/200\n",
            "30/30 - 0s - loss: 0.1768 - accuracy: 0.9600\n",
            "Epoch 106/200\n",
            "30/30 - 0s - loss: 0.1756 - accuracy: 0.9600\n",
            "Epoch 107/200\n",
            "30/30 - 0s - loss: 0.1732 - accuracy: 0.9533\n",
            "Epoch 108/200\n",
            "30/30 - 0s - loss: 0.1713 - accuracy: 0.9533\n",
            "Epoch 109/200\n",
            "30/30 - 0s - loss: 0.1697 - accuracy: 0.9600\n",
            "Epoch 110/200\n",
            "30/30 - 0s - loss: 0.1685 - accuracy: 0.9600\n",
            "Epoch 111/200\n",
            "30/30 - 0s - loss: 0.1674 - accuracy: 0.9533\n",
            "Epoch 112/200\n",
            "30/30 - 0s - loss: 0.1648 - accuracy: 0.9600\n",
            "Epoch 113/200\n",
            "30/30 - 0s - loss: 0.1643 - accuracy: 0.9600\n",
            "Epoch 114/200\n",
            "30/30 - 0s - loss: 0.1628 - accuracy: 0.9733\n",
            "Epoch 115/200\n",
            "30/30 - 0s - loss: 0.1605 - accuracy: 0.9533\n",
            "Epoch 116/200\n",
            "30/30 - 0s - loss: 0.1588 - accuracy: 0.9533\n",
            "Epoch 117/200\n",
            "30/30 - 0s - loss: 0.1574 - accuracy: 0.9600\n",
            "Epoch 118/200\n",
            "30/30 - 0s - loss: 0.1565 - accuracy: 0.9600\n",
            "Epoch 119/200\n",
            "30/30 - 0s - loss: 0.1546 - accuracy: 0.9533\n",
            "Epoch 120/200\n",
            "30/30 - 0s - loss: 0.1540 - accuracy: 0.9667\n",
            "Epoch 121/200\n",
            "30/30 - 0s - loss: 0.1522 - accuracy: 0.9533\n",
            "Epoch 122/200\n",
            "30/30 - 0s - loss: 0.1506 - accuracy: 0.9533\n",
            "Epoch 123/200\n",
            "30/30 - 0s - loss: 0.1500 - accuracy: 0.9667\n",
            "Epoch 124/200\n",
            "30/30 - 0s - loss: 0.1487 - accuracy: 0.9600\n",
            "Epoch 125/200\n",
            "30/30 - 0s - loss: 0.1479 - accuracy: 0.9600\n",
            "Epoch 126/200\n",
            "30/30 - 0s - loss: 0.1474 - accuracy: 0.9533\n",
            "Epoch 127/200\n",
            "30/30 - 0s - loss: 0.1448 - accuracy: 0.9667\n",
            "Epoch 128/200\n",
            "30/30 - 0s - loss: 0.1441 - accuracy: 0.9533\n",
            "Epoch 129/200\n",
            "30/30 - 0s - loss: 0.1425 - accuracy: 0.9533\n",
            "Epoch 130/200\n",
            "30/30 - 0s - loss: 0.1420 - accuracy: 0.9733\n",
            "Epoch 131/200\n",
            "30/30 - 0s - loss: 0.1401 - accuracy: 0.9533\n",
            "Epoch 132/200\n",
            "30/30 - 0s - loss: 0.1393 - accuracy: 0.9533\n",
            "Epoch 133/200\n",
            "30/30 - 0s - loss: 0.1379 - accuracy: 0.9533\n",
            "Epoch 134/200\n",
            "30/30 - 0s - loss: 0.1367 - accuracy: 0.9600\n",
            "Epoch 135/200\n",
            "30/30 - 0s - loss: 0.1363 - accuracy: 0.9667\n",
            "Epoch 136/200\n",
            "30/30 - 0s - loss: 0.1352 - accuracy: 0.9600\n",
            "Epoch 137/200\n",
            "30/30 - 0s - loss: 0.1338 - accuracy: 0.9533\n",
            "Epoch 138/200\n",
            "30/30 - 0s - loss: 0.1327 - accuracy: 0.9600\n",
            "Epoch 139/200\n",
            "30/30 - 0s - loss: 0.1325 - accuracy: 0.9667\n",
            "Epoch 140/200\n",
            "30/30 - 0s - loss: 0.1309 - accuracy: 0.9600\n",
            "Epoch 141/200\n",
            "30/30 - 0s - loss: 0.1301 - accuracy: 0.9600\n",
            "Epoch 142/200\n",
            "30/30 - 0s - loss: 0.1289 - accuracy: 0.9533\n",
            "Epoch 143/200\n",
            "30/30 - 0s - loss: 0.1289 - accuracy: 0.9533\n",
            "Epoch 144/200\n",
            "30/30 - 0s - loss: 0.1273 - accuracy: 0.9533\n",
            "Epoch 145/200\n",
            "30/30 - 0s - loss: 0.1275 - accuracy: 0.9533\n",
            "Epoch 146/200\n",
            "30/30 - 0s - loss: 0.1258 - accuracy: 0.9600\n",
            "Epoch 147/200\n",
            "30/30 - 0s - loss: 0.1256 - accuracy: 0.9533\n",
            "Epoch 148/200\n",
            "30/30 - 0s - loss: 0.1255 - accuracy: 0.9533\n",
            "Epoch 149/200\n",
            "30/30 - 0s - loss: 0.1232 - accuracy: 0.9600\n",
            "Epoch 150/200\n",
            "30/30 - 0s - loss: 0.1230 - accuracy: 0.9533\n",
            "Epoch 151/200\n",
            "30/30 - 0s - loss: 0.1216 - accuracy: 0.9600\n",
            "Epoch 152/200\n",
            "30/30 - 0s - loss: 0.1219 - accuracy: 0.9533\n",
            "Epoch 153/200\n",
            "30/30 - 0s - loss: 0.1198 - accuracy: 0.9600\n",
            "Epoch 154/200\n",
            "30/30 - 0s - loss: 0.1198 - accuracy: 0.9600\n",
            "Epoch 155/200\n",
            "30/30 - 0s - loss: 0.1191 - accuracy: 0.9533\n",
            "Epoch 156/200\n",
            "30/30 - 0s - loss: 0.1179 - accuracy: 0.9533\n",
            "Epoch 157/200\n",
            "30/30 - 0s - loss: 0.1180 - accuracy: 0.9600\n",
            "Epoch 158/200\n",
            "30/30 - 0s - loss: 0.1171 - accuracy: 0.9600\n",
            "Epoch 159/200\n",
            "30/30 - 0s - loss: 0.1167 - accuracy: 0.9600\n",
            "Epoch 160/200\n",
            "30/30 - 0s - loss: 0.1169 - accuracy: 0.9600\n",
            "Epoch 161/200\n",
            "30/30 - 0s - loss: 0.1151 - accuracy: 0.9600\n",
            "Epoch 162/200\n",
            "30/30 - 0s - loss: 0.1141 - accuracy: 0.9600\n",
            "Epoch 163/200\n",
            "30/30 - 0s - loss: 0.1140 - accuracy: 0.9600\n",
            "Epoch 164/200\n",
            "30/30 - 0s - loss: 0.1122 - accuracy: 0.9667\n",
            "Epoch 165/200\n",
            "30/30 - 0s - loss: 0.1119 - accuracy: 0.9533\n",
            "Epoch 166/200\n",
            "30/30 - 0s - loss: 0.1123 - accuracy: 0.9600\n",
            "Epoch 167/200\n",
            "30/30 - 0s - loss: 0.1117 - accuracy: 0.9600\n",
            "Epoch 168/200\n",
            "30/30 - 0s - loss: 0.1114 - accuracy: 0.9600\n",
            "Epoch 169/200\n",
            "30/30 - 0s - loss: 0.1115 - accuracy: 0.9533\n",
            "Epoch 170/200\n",
            "30/30 - 0s - loss: 0.1088 - accuracy: 0.9600\n",
            "Epoch 171/200\n",
            "30/30 - 0s - loss: 0.1089 - accuracy: 0.9533\n",
            "Epoch 172/200\n",
            "30/30 - 0s - loss: 0.1082 - accuracy: 0.9600\n",
            "Epoch 173/200\n",
            "30/30 - 0s - loss: 0.1081 - accuracy: 0.9600\n",
            "Epoch 174/200\n",
            "30/30 - 0s - loss: 0.1070 - accuracy: 0.9667\n",
            "Epoch 175/200\n",
            "30/30 - 0s - loss: 0.1071 - accuracy: 0.9533\n",
            "Epoch 176/200\n",
            "30/30 - 0s - loss: 0.1068 - accuracy: 0.9533\n",
            "Epoch 177/200\n",
            "30/30 - 0s - loss: 0.1060 - accuracy: 0.9533\n",
            "Epoch 178/200\n",
            "30/30 - 0s - loss: 0.1050 - accuracy: 0.9600\n",
            "Epoch 179/200\n",
            "30/30 - 0s - loss: 0.1044 - accuracy: 0.9600\n",
            "Epoch 180/200\n",
            "30/30 - 0s - loss: 0.1044 - accuracy: 0.9533\n",
            "Epoch 181/200\n",
            "30/30 - 0s - loss: 0.1035 - accuracy: 0.9600\n",
            "Epoch 182/200\n",
            "30/30 - 0s - loss: 0.1032 - accuracy: 0.9600\n",
            "Epoch 183/200\n",
            "30/30 - 0s - loss: 0.1027 - accuracy: 0.9533\n",
            "Epoch 184/200\n",
            "30/30 - 0s - loss: 0.1019 - accuracy: 0.9600\n",
            "Epoch 185/200\n",
            "30/30 - 0s - loss: 0.1048 - accuracy: 0.9533\n",
            "Epoch 186/200\n",
            "30/30 - 0s - loss: 0.1025 - accuracy: 0.9667\n",
            "Epoch 187/200\n",
            "30/30 - 0s - loss: 0.1011 - accuracy: 0.9600\n",
            "Epoch 188/200\n",
            "30/30 - 0s - loss: 0.1013 - accuracy: 0.9533\n",
            "Epoch 189/200\n",
            "30/30 - 0s - loss: 0.1002 - accuracy: 0.9533\n",
            "Epoch 190/200\n",
            "30/30 - 0s - loss: 0.0993 - accuracy: 0.9600\n",
            "Epoch 191/200\n",
            "30/30 - 0s - loss: 0.0990 - accuracy: 0.9600\n",
            "Epoch 192/200\n",
            "30/30 - 0s - loss: 0.1004 - accuracy: 0.9533\n",
            "Epoch 193/200\n",
            "30/30 - 0s - loss: 0.0987 - accuracy: 0.9533\n",
            "Epoch 194/200\n",
            "30/30 - 0s - loss: 0.0978 - accuracy: 0.9600\n",
            "Epoch 195/200\n",
            "30/30 - 0s - loss: 0.0988 - accuracy: 0.9533\n",
            "Epoch 196/200\n",
            "30/30 - 0s - loss: 0.0967 - accuracy: 0.9600\n",
            "Epoch 197/200\n",
            "30/30 - 0s - loss: 0.0968 - accuracy: 0.9533\n",
            "Epoch 198/200\n",
            "30/30 - 0s - loss: 0.0976 - accuracy: 0.9667\n",
            "Epoch 199/200\n",
            "30/30 - 0s - loss: 0.0967 - accuracy: 0.9533\n",
            "Epoch 200/200\n",
            "30/30 - 0s - loss: 0.0953 - accuracy: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2J4PvOS14K2"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-LOyxbAlTNs"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdHmLcxvPo8",
        "outputId": "ed6d6ee9-59bb-4744-f0e1-64a80e5c1147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa1844e8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa184d33a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa1866fb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa1a01d9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa183c336a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa189613510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Baseline: 96.67% (4.47%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBn6fw0e9l-N"
      },
      "source": [
        "losses = hist.history['loss']\n",
        "epochs = hist.epoch"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAOOFil92ml",
        "outputId": "8784faaf-f19c-46f0-a1f5-aa3310471939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs, losses)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel('losses')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFZ-p5Daeluq",
        "outputId": "bf6c96d4-978d-4215-8eb4-9307877019aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs[120:], losses[120:])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel('losses')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV5fnH8c+VSUjYCSvsLSBDAogC7m3VWnBvqaNVa2ut1vGzaodKra3WPaqouGvFiVYRBwoElKWAYQcEApEdICTX74/zUI94CGGcPCfJ9/16nRfnPPczvueQnCv3M+7H3B0REZEdJYUdQEREEpMKhIiIxKQCISIiMalAiIhITCoQIiISkwqEiIjEpAIhUsuZ2UIzOzLsHJJ4VCCkWqqpX2pm9qGZbTazDVGP18POJbVTStgBRGorM0t297IYTVe4+2NVHkhkB+pBSI1iZulm9nczWxY8/m5m6UFbtpm9YWZrzKzYzD42s6Sg7TozW2pm681sjpkdsZP1P2lmD5nZe8G8482sbVR7t6CtOFjPaTss+6CZvWVmG4HDdvO9HWpmhWZ2g5mtCnpRZ0e1NzCzUWZWZGaLzOym7e8vaP+5mX0d5P7KzA6IWn0fM5tuZmvN7AUzq7M72aRmUoGQmuZG4ECgD9AbGADcFLRdAxQCOUAz4AbAzawrcAXQ393rAccACyvYxtnA7UA28CXwLICZZQLvAaOBpsAZwANm1j1q2bOAPwH1gE/24P01D7abC5wPPBLkB7gPaAB0AA4BzgMuDLINB/4QTKsPnASsjlrvacCxQHugF3DBHmSTGkYFQmqas4Hb3H2luxcBtwLnBm2lQAugrbuXuvvHHhmMrAxIB7qbWaq7L3T3eRVs4013/8jdtxApSIPMrDVwIrDQ3f/l7tvc/QvgFWB41LKvufun7l7u7pt3sv57g17O9sftO7Tf7O5b3H088CZwmpklEylIv3f39e6+ELg76r2PAO5y98keUeDui6K36e7L3L0YeJ1IgZVaTgVCapqWQPQX36JgGsBIoAB418zmm9n1AO5eAFxN5C/slWb2vJm1ZOeWbH/i7huA4mAbbYGB0V/uRApW81jLVuAqd28Y9bg5qu07d98Y4/1lA6kx3ntu8Lw1UFHRWx71fBOQVYmcUsOpQEhNs4zIF/V2bYJpBH9ZX+PuHYjsYvnN9mMN7j7a3QcHyzpwZwXbaL39iZllAY2DbSwBxu/w5Z7l7pdHLbu3wyc3CnZl7fj+VhHpIe343pcGz5cAHfdy21LLqEBIdZZqZnWiHinAc8BNZpZjZtnA/wHPAJjZiWbWycwMWEtk11K5mXU1s8ODg9mbgRKgvILtHm9mg80sjcixiM/dfQnwBtDFzM41s9Tg0d/M9tvH7/tWM0szsyFEdmu9FJwN9SLwJzOrFxw4/8329w48BvzWzPpZRKfog+sisahASHX2FpEv8+2PPwB/BPKB6cAMYGowDaAz8F9gA/AZ8IC7jyNy/OEOIn+FLydygPn3FWx3NHALkV1L/YBzINJDAY4mcixgWbCuO4P1745/7nAdxJSotuXAd8H6nwUuc/fZQduVwEZgPpED4KOBJ4JsLxE5OD4aWA/8h0jPR2SnTDcMEqk8M3sSKHT3m3Y1bxy2fSjwjLu3quptS+2kHoSIiMSkAiEiIjFpF5OIiMSkHoSIiMRUYwbry87O9nbt2oUdQ0SkWpkyZcoqd8+J1VZjCkS7du3Iz88PO4aISLViZot21qZdTCIiEpMKhIiIxKQCISIiMalAiIhITCoQIiISkwqEiIjEpAIhIiIx1foCsbm0jDvens2S4k1hRxERSSi1vkCs3riVZz5fxHWvTKe8XONSiYhsV+sLRG7DDG44fj8mzFvNs5MWhx1HRCRh1PoCAXDmgNYM6ZzNX976WruaREQCKhCAmXHHz3qRZMa1L0/TriYREVQg/ie3YQY3n7gfn88v5pmJOx27SkSk1ohrgTCzY81sjpkVmNn1MdqHmtlUM9tmZsN2aCszsy+Dx5h45tzutLzWHNIlh7+8NZtXvyhkW1l5VWxWRCQhxa1AmFkycD9wHNAdONPMuu8w22LgAmB0jFWUuHuf4HFSvHJGi+xq2p922Zn8+oVpHPm38byYv4RSFQoRqYXi2YMYABS4+3x33wo8D5wcPYO7L3T36UDCfAO3aJDBm1cO5uFz+5FVJ4XfvTydI/82nqVrSsKOJiJSpeJZIHKBJVGvC4NplVXHzPLN7HMzOyXWDGZ2STBPflFR0d5k/YGkJOOYHs15/YrBPH5+HsUbtnLJqHxKtpbts22IiCS6RD5I3dbd84CzgL+bWccdZ3D3R9w9z93zcnJi3jFvr5gZR+zXjH+c2Yevvl3Hda9Mx11nOIlI7RDPArEUaB31ulUwrVLcfWnw73zgQ6Dvvgy3Ow7v1ozfHt2VMdOW8fBH88OKISJSpeJZICYDnc2svZmlAWcAlTobycwamVl68DwbOBj4Km5JK+EXh3bkhF4tuPOd2Xw4Z2WYUUREqkTcCoS7bwOuAMYCXwMvuvssM7vNzE4CMLP+ZlYIDAceNrNZweL7AflmNg0YB9zh7qEWCDNj5LBedGten188O5WX8pdod5OI1GhWU77k8vLyPD8/P+7bWbFuM1c99wUTFxTzk94t+eMpPWmQkRr37YqIxIOZTQmO9/5IIh+kTkjN6tdh9M8P5NpjuvLWjG85/h8f82nBKvUmRKTGUYHYA8lJxi8P68TLlw0iOck4+7GJnHjfJ7yUv4TNpToVVkRqBhWIvdC3TSPGXj2UP/90f0rLyrn25ekcdMcHjJm2LOxoIiJ7TQViL2WkJXPWwDaMvXooo0cMpHn9Otw6ZhZbtqknISLVmwrEPmJmHNQpm98f343VG7fyxrRvw44kIrJXVCD2scGdsunUNIsnJyzUgWsRqdZUIPYxM+P8g9oxY+lapi5eE3YcEZE9pgIRB6f2zaVenRSenLAw7CgiIntMBSIOMtNTOC2vNW/P+JblazeHHUdEZI+oQMTJeYPaUubOs7p9qYhUUyoQcdK2SSZHdGvK6ImLdcqriFRLKhBxdMFB7Vm9cSsPfTif8nKd0SQi1YsKRBwd3KkJR3Rryj3/nctpD3/G3BXrw44kIlJpKhBxZGY8dn4eI4f1oqBoAyfc+zF/HTuHrdsS5hbcIiI7pQIRZ2bG8LzWvP+bQ/hJr5b8c1wBf37r67BjiYjsUkrYAWqLJlnp/O30PtTPSOXJCQs5tmdzDuzQJOxYIiI7pR5EFfvdsV1p26Quv3t5Ohu3bAs7jojITqlAVLG6aSnc9bNeLC7exJ3vzA47jojITqlAhGBghyZceHA7Rn22iAnzVoUdR0QkJhWIkPzumG60C3Y1FazcEHYcEZEfUYEISUZaMnef1pvVG7Zy5N/GM+KpfCYvLNYQ4SKSMFQgQtSvbWM+vu4wrjqiM1MWFTP8oc8445HP2bRVB69FJHwqECHLzkrnN0d1YcL1R3DTCfsxcUEx948rCDuWiIgKRKLISEtmxJAOnNo3l0c/WsDCVRvDjiQitZwKRIK5/rhupKUkcfsbX4UdRURqORWIBNO0fh2uOqIT789eybjZK8OOIyK1WFwLhJkda2ZzzKzAzK6P0T7UzKaa2TYzGxajvb6ZFZrZP+OZM9FccFB7OuRkcuvrs3QvCREJTdwKhJklA/cDxwHdgTPNrPsOsy0GLgBG72Q1twMfxStjokpLSeKWn/Rg4epNPP7JgrDjiEgtFc8exACgwN3nu/tW4Hng5OgZ3H2hu08HfjT+tZn1A5oB78YxY8I6pEsOR3dvxt/encv94woo0w2HRKSKxbNA5AJLol4XBtN2ycySgLuB3+5ivkvMLN/M8ouKivY4aKL662m9ObZnc0aOncNZj37OsjUlYUcSkVokUQ9S/wJ4y90LK5rJ3R9x9zx3z8vJyamiaFWnfp1U7juzL38d3puZS9dy3D8+5r2vVoQdS0RqiXgWiKVA66jXrYJplTEIuMLMFgJ/Bc4zszv2bbzqwcwY1q8Vb141hDaN6/LLZ6fy5ZI1YccSkVogngViMtDZzNqbWRpwBjCmMgu6+9nu3sbd2xHZzTTK3X90FlRt0i47k1EXDaBp/XR+8cwUVm/YEnYkEanh4lYg3H0bcAUwFvgaeNHdZ5nZbWZ2EoCZ9TezQmA48LCZzYpXnpqgUWYaD53Tj9Ubt3Llc1+wrUz3thaR+LGaMnpoXl6e5+fnhx2jSrw8pZDfvjSNS4d24PfH7xd2HBGpxsxsirvnxWpL1IPUUoFh/Vpx7oFtefij+bwxfVnYcUSkhlKBqKZuPrE7eW0b8ZsXpvFpge5KJyL7ngpENZWWksTj5/enQ04mPx+Vz9TF34UdSURqGBWIaqxB3VRGXTyAnHrpXPivycxevi7sSCJSg6hAVHNN69XhmYsHkpGazLmPT+Kzeasp17AcIrIPqEDUAK0b1+WZEQNwd8589HOG3DWOO9+ZzZzl68OOJiLVmE5zrUE2btnGe1+t4D9fLuXjb1ZRVu5cfWRnrj6yS9jRRCRBVXSaa0pVh5H4yUxP4ZS+uZzSN5dVG7bw5ze/5u///YZkM648onPY8USkmlGBqKGys9IZObw3AHe/N5ekJOOXh3UKOZWIVCcqEDVYcpIxcnhvytwZOXYOKUnGpYd0DDuWiFQTKhA1XHKScffw3pQ7/OXt2TTJSmdYv1ZhxxKRakAFohZISU7ib6f1ZvWGLdzw6gw65mTSt02jsGOJSILTaa61RGpyEvefdQDN6qdz2TNTWLluc9iRRCTBqUDUIo0y03j0vDzWb97Gpc9MYcu2srAjiUgCU4GoZbo1r8/dw3vzxeI13PTqTGrKdTAisu+pQNRCx+3fgquO6MxLUwr505tfq0iISEw6SF1L/frIzqwrKeWxTxYAcOMJ+2FmIacSkUSiAlFLmRm3/KQ7gIqEiMSkAlGL7VgkijZs4fBuTenWvD4dcjJJTdYeSJHaTAWiltteJNJTknji0wW89mXkFqZpyUkMz2vFH0/pqV6FSC2lAiGYGb8/fj9+e0xX5hdt5Otv1/HhnJU8O3ExvVs15LT+rcOOKCIhUIGQ/0lNTqJr83p0bV6Pk3q3ZOX6Lfzh9Vn0b9+Y9tmZYccTkSqmncwSU1KScfdpvUlNTuLq57+gtKw87EgiUsVUIGSnWjTI4M8/3Z9phWv5x3+/CTuOiFQxFQip0Am9WjC8Xyse+LCACQWrwo4jIlUorgXCzI41szlmVmBm18doH2pmU81sm5kNi5reNpj+pZnNMrPL4plTKnbLST1o1ySTC/41macmLNSV1yK1RNwKhJklA/cDxwHdgTPNrPsOsy0GLgBG7zD9W2CQu/cBBgLXm1nLeGWVimWlp/DK5QcxuHM2t4yZxS+encq6zaVhxxKROItnD2IAUODu8919K/A8cHL0DO6+0N2nA+U7TN/q7luCl+lxzimV0CgzjcfOy+OG47vx3lcrOPHeT5izfH3YsUQkjuL5xZsLLIl6XRhMqxQza21m04N13Onuy/ZxPtlNSUnGJUM78sKlg9iyrYyzH5vIotUbw44lInGSsH+Zu/sSd+8FdALON7NmO85jZpeYWb6Z5RcVFVV9yFqqX9tGPDtiIGXl5Zzz+ETdfEikhopngVgKRF+C2yqYtluCnsNMYEiMtkfcPc/d83JycvY4qOy+Tk3r8eSFAyjesJVzH5/E2k06JiFS08TzSurJQGcza0+kMJwBnFWZBc2sFbDa3UvMrBEwGLgnbkllj/Ru3ZBHzsvjwn9N5oInJ3Fy75aUljml5eU0yEjltLzWGvBPpBqLW4Fw921mdgUwFkgGnnD3WWZ2G5Dv7mPMrD/wKtAI+ImZ3eruPYD9gLvNzAED/uruM+KVVfbcwZ2yuffMPlz13Jd8sXjND9qWr93MNUd3DSmZiOwtqynntOfl5Xl+fn7YMWqtjVu2sXVbOakpSaQkGTf9Zyb/nlrIi5cOIq9d47DjichOmNkUd8+L1ab+v+wTmekpNMpMIys9hTqpydzyk+7kNsrg1y9+yXpdMyFSLalASFzUq5PKPaf1Yel3Jdz6+ldhxxGRPaDhviVu8to15orDOnHvBwUM6tCEdtmZzFu5gYKiDbRoUIcLD24fdkQRqcBuF4jgrKLWwRXQIhW68ojOjJ9bxDUvTfvftCSDcodOTbMY0lmnJ4skqkodpDazD4GTiBSUKcBK4FN3/01c0+0GHaROXMvWlPDWjG9p1ySTTk2zaFo/nRPv/YTS8nLGXj2UumnqyIqEZV8cpG7g7uuAU4FR7j4QOHJfBZSarWXDDEYM6cCR3ZvRLjuTumkp/OXU/VlSXMI9780NO56I7ERlC0SKmbUATgPeiGMeqSUGdmjCWQPb8PgnC5heuGbXC4hIlatsgbiNyAVv89x9spl1AHSLMdkr1x/XjeysdK57ZYZuaSqSgHShnIRq7KzlXPr0FI7r2ZwB7RvTulFdWjeuS9smdamTmhx2PJEar6JjEJU6OmhmXYAHgWbu3tPMegEnufsf92FOqYWO6dGcCw5qxwuTl/D2zOU/aGvZoA7tczLplJPFLw/rRNP6dUJKKVI7VfYspvHAtcDD7t43mDbT3XvGOV+lqQdRvbk7qzduZUnxJhYXb2LR6k0sWLWRBas2MmvZWo7u0Zz7zzog7JgiNc5e9yCAuu4+ycyip23b62QiATMjOyud7Kx0+rZp9IO2u96ZzYPj5zG/aAMdcrJCSihS+1T2IPUqM+sIOICZDSNy32iRuLtocHvSU5J48MN5YUcRqVUqWyB+CTwMdDOzpcDVwOVxSyUSJTsrnTP6t+HVL5aydE1J2HFEao1KFQh3n+/uRwI5QDd3H+zuC+OaTCTKJUM7APDoR/NDTiJSe1SqQJjZr8ysPrAJuMfMpprZ0fGNJvK9lg0zOPWAXJ6btJhVG7aEHUekVqjsLqaLgqE2jgaaAOcCd8QtlUgMlx3Ska1l5TzxyYKwo4jUCpU9i2n76UvHExmLaZbtcEqTSLx1yMni+P1b8PRni+jesj5dmtWjXZNM0lJ0WxOReKhsgZhiZu8C7YHfm1k9QGMjSJW78vBOfDSniCtGfwFAcpLRo2V9HjynH7kNM0JOJ1KzVPZCuSSgDzDf3deYWWOgVSLdE0IXytUeJVvLmFe0gXlFG5i7Yj2jJiyiQ04mL1w6SMNziOymfXGh3CDgS3ffaGbnAAcA/9hXAUV2R0ZaMj1zG9AztwEA++c25LJnpnDr61/xl1P3DzmdSM1R2Z23DwKbzKw3cA0wDxgVt1Qiu+HYns25/NCOPDdpMS9OXvKDtpXrNrNy3eaQkolUb5XtQWxzdzezk4F/uvvjZnZxPIOJ7I5rjurC9MI13PTaTFo2zGBx8SbGTFvKxAXF5GSlM/7aw8hI0+4nkd1R2R7EejP7PZHTW98Mjkmkxi+WyO5JSU7i3jP6kp2ZxjmPT+SGV2ewct0Wzh7YhpXrt/DM54vCjihS7VS2B3E6cBaR6yGWm1kbYGT8YonsviZZ6TxxYX/enrGco7o3o0fL+pgZi1Zv4qHx8zhrYBsy03X/a5HKquxQG8uBZ4EGZnYisNnddQxCEk635vX59VFd6JnbgO2X6vz6qC6s3riVpz5bGGo2keqmskNtnAZMAoYTuS/1xGBE110td6yZzTGzAjO7Pkb70GDYjm3R6zOzPmb2mZnNMrPpZnZ65d+SyA8d0KYRh3XN4ZGP5rN+c2nYcUSqjcoeg7gR6O/u57v7ecAA4OaKFjCzZOB+4DigO3CmmXXfYbbFwAXA6B2mbwLOc/cewLHA382sYSWzivzIr4/qwppNpTz56cKwo4hUG5UtEEnuvjLq9epKLDsAKAhGgt0KPA+cHD2Duy8MLrYr32H6XHf/Jni+DFhJZCRZkT3Sq1VDjtyvGY9+PJ+1JepFiFRGZY/YvWNmY4HngtenA2/tYplcIPqk9EJg4O7FAzMbAKQRufZix7ZLgEsA2rRps7urllrm6iM7c+J9KzjviUnkZKVT7o67M6RzDucc2FZjOonsoLIHqa8FHgF6BY9H3P26eAYDMLMWwNPAhe7+o7Gf3P0Rd89z97ycHHUwpGI9cxvw8yHt2VJaxtI1Jaxcv5kl35Vw2xtfcczfP+LdWcupzNAzIrVFpc/5c/dXgFd2Y91LgdZRr1sF0yoluP/Em8CN7v75bmxXZKduPOGHh8HcnQ/nFPHHN7/ikqenMKhDE+4a1ovWjeuGlFAkcVTYgzCz9Wa2LsZjvZmt28W6JwOdzay9maUBZwBjKhMqmP9VIkOLv1yZZUT2hJlxWLemvHP1UG4/uQczl63lnMcnUrReNyUSqbBAuHs9d68f41HP3evvYtltwBXAWOBr4MXgPhK3mdlJAGbW38wKiZw++7CZzQoWPw0YClxgZl8Gjz57+V5Fdio1OYlzB7XjqYsGsHLdFs57YpIOZkutV6nhvqsDDfct+8r4uUWMeGoyfVs3YtTFAzSEuNRo+2K4b5Fa45AuOfzttD5c9fwXXPr0FA7rmsO6zdtYV1JKemoSlx7Skfp1NBSZ1HwqECIx/KR3S9aUlPJ/r81k/NwiADLTkikpLePdWSt4/Pz+tGmiA9lSs2kXk0gFijduxYCsOimkJicxoWAVlz87leQk46Fz+jGgfeOwI4rslYp2MenKIJEKNM5Mo1FmGqnJkV+Vgzpl8+ovDqJhRipnP/Y5T01YyMYt20JOKRIf6kGI7IG1m0r55eipfFKwirSUJIZ0yuaYHs1pl53J4uJNLF69kSXflXBYt6ac1Ltl2HFFdkoHqUX2sQZ1Uxl10QAmLSxm7KzlvDtrBe/P/n64siSDumkpvDNzOXltG9GyYUaIaUX2jHoQIvuAuzNr2TpWbdhCm8Z1adWoLivWbeaoe8ZzWNemPHhOv7AjisSkYxAicWZm9MxtwKFdm9IhJ4u0lCRaN67LlYd35u2Zy/93JpRIdaICIRJHI4a0p0N2Jre8NpPNpWVhxxHZLSoQInGUnpLMbSf3ZOHqTTzy0fyw44jsFhUIkTgb3DmbE3q14P5xBSxevSnsOCKVpgIhUgVuPqE7qclJnPfERJYUq0hI9aACIVIFmjeow1MXDeC7TaWc+uAEZi1bG3YkkV1SgRCpIv3aNuLlywaRkmSc8fDnfDZvddiRRCqk6yBEqtiyNSWc/8QkFq7eSNsmmSSbkZxkNMlK446f9SJXF9VJFdJ1ECIJpGXDDF66bBBn9G9D56ZZtG1Sl5YN6zB5YTG3jpm16xWIVBENtSESgoZ107j9lJ4/mPbAhwXc9c4cxs1eyWHdmoaUTOR76kGIJIgRgzvQISeTW8bM0kV1khBUIEQSRFpKEref3JPFxZt4aPy8sOOIqECIJJKDO2VzYq8WPPDhPF1UJ6FTgRBJMDed0J3UJOPG/8xgxbrNP2qfu2I9d74zm7vfncOqDVtCSCi1hU5zFUlAT366gD+8/hUA++c24PBuTamfkcp/vljKjKVrSU4y3J30lGTOO6gtlw7tSOPMtJBTS3VU0WmuKhAiCWrO8vX89+sVfDB7JVMXf4c79GhZn58d0IqT+rRkzaZS7vvgG8ZMW0ZGajIn98nlyP2aclDHbDLSkv+3nrJyZ21JqQqIxKQCIVLNFW/cyrqSUtplZ/6orWDleu4fN493Zy1n49Yy0lOSOLBDE8xg8epNFH5Xwtaych44+wCO379FCOklkalAiNQCW7aVMWlBMe9/vZJPClaRnpJE2yZ1ad24Lm9M+5bchhm8eNmgsGNKgtE9qUVqgfSUZIZ0zmFI55wftTWqm8Ydb8+mYOV6OjWtF0I6qY7iehaTmR1rZnPMrMDMro/RPtTMpprZNjMbtkPbO2a2xszeiGdGkdpgWL9WpCYboycuCTuKVCNxKxBmlgzcDxwHdAfONLPuO8y2GLgAGB1jFSOBc+OVT6Q2yc5K55gezXllaqGu0pZKi2cPYgBQ4O7z3X0r8DxwcvQM7r7Q3acD5Tsu7O7vA+vjmE+kVjlrQBvWlpTy1oxvw44i1UQ8C0QuEN2fLQym7TNmdomZ5ZtZflFR0b5ctUiNM6hjE9pnZzJ64uKwo0g1Ua2vpHb3R9w9z93zcnJ+fGBORL5nZpw5oDX5i75j7gp1zmXX4lkglgKto163CqaJSEiG9WtNWnKSehFSKfE8zXUy0NnM2hMpDGcAZ8VxeyKyC40z0zimZ3NemVJI0fotFK4pYel3JSQZXH9cN37aNxczCzumJIi49SDcfRtwBTAW+Bp40d1nmdltZnYSgJn1N7NCYDjwsJn973ZaZvYx8BJwhJkVmtkx8coqUptcPLg9KcnG19+uo36dFI7crym5jTL4zYvTuPDJySxbUxJ2REkQupJaRCgrd56asJCRY+eQnGRcdHA7WjWuS+O6aTTOSqNrs3pkpuu62ppIV1KLSIWSk4yLBrfnyP2accOrM7j3g4IftOc2zOCZEQNpH2MsKKm51IMQkR/ZuGUbxRu3UrxxK4XflXDzazNJTjKeHTGQLs00VEdNUlEPolqf5ioi8ZGZnkLrxnXp3bohJ/RqwQuXHIgBpz/8GTMK14YdT6qIehAiUimLVm/krEcnsq6klJ/1a8WaTVsp3lTK2pJSureoz3E9mzOoYxNSk/V3Z3Wi4b5FZJ9YtqaEEU/ls7h4E40yU2mcmU5mWjJfLlnDpq1lNMhI5ajuzbjy8E60baLjFdWBCoSIxNXm0jI+/mYVb8/8lrEzl+PADcfvx9kD2+i6igSnAiEiVWbZmhJ+9/J0PilYxZDO2dw1rBctGmSEHUt2QgepRaTKtGyYwdMXD+D2U3qSv/A7jrnnIybMWxV2LNkDKhAiss+ZGece2Ja3fzWE5g3qcMETk3lj+rKwY8luUoEQkbhpl53JS5ceRJ/WDbnyuS/416cLwo4ku0EFQkTiqkHdVEZdPICjuzfj1te/4o9vfKW72lUTKhAiEnd1UpN54Ox+nHtgWx77ZAGHjBzHM58vYuu2H91Mcp+ZsqiYP7/1NTXlRJwwaCwmEakSyUnG7af05Ce9WzJy7Gxu+s9MHvloPmcNbENOVjoNMlJpWDeVrs3rUa9O6l5v7+5351qh4/QAAA96SURBVDJh3moGtm/MEfs12wfvoPZRgRCRKjWgfWNevHQQH84t4q9j53DH27N/0J5TL52/n96Hgztl7/E2lhRvYsK81QDc90EBh3drqusx9oAKhIhUOTPjsK5NObRLDmuC4TrWlpSyYt1m7nxnNuc8PpFfHtqJq4/sTMoeDN3xytRCzODyQzrywIfz+LRgNYM773nBqa10DEJEQmNmNMpMo112Jr1bN+ToHs15/crBDDugFf8cV8CZj37OrGVrd+s4Qnm588rUQg7q2IRfHdmZZvXTue+Db+L4LmouFQgRSSh101IYObw395zem6+WreOEez9h8J3juPk/M/lwzkpKyyo+sD1xQTFLiksY1q8V6SnJXDq0IxMXFDNpQXEVvYOaQwVCRBLST/u2YvzvDuOOU/ene8v6vDylkAv+NZkhd47j/nEFFG/cGnO5l6YsoV56Csf2aAHAmQPakJ2Vxj/HFcScX3ZOxyBEJGFlZ6VzxoA2nDGgDZtLyxg/t4inP1vEyLFzuPf9b/hp31x+e0xXsrPSAdiwZRtvz1jOKX1bkpGWDEBGWjIjhnTgjrdnM23JGnq3bhjmW6pW1IMQkWqhTmoyx/RozjMjBvLur4dy6gGt+PcXSznx3k+Yuvg7AN6cvoyS0jKG9Wv9g2XPObAtDTJSufu9ubouYjeoQIhItdOlWT3+cur+vPqLg0hLSeL0hz/jqQkLeSm/kA45mRzQ5oe9hKz0FH51RGc+mlvEg+PnhZS6+lGBEJFqq0fLBrx+xWCGds7hljGzyF/0HcP7tY55zcOFB7fjxF4tGDl2DuPmrAwhbfWjAiEi1VqDuqk8el4e1xzVhU5Ns/hZv9yY85kZdw3rRbfm9bnquS9YsGpjFSetfnTDIBGpVZYUb+Kkf35Ck6x0/nVBf5atKWHuyg0sWrWR4/ZvTr+2jcOOWKV0RzkRkSgTClZx7hOTKCv//vsvySA1OYlHz8tjaJecENNVrYoKhE5zFZFa56BO2Yy6aABff7uOzs3q0blpFukpSZzz+CRGjMrnkXP7cWjXpmHHDF1cj0GY2bFmNsfMCszs+hjtQ81sqpltM7NhO7Sdb2bfBI/z45lTRGqfgztlM2JIBw7pkkPLhhk0yUpn9IiBdG6axSWjpvDB7BWVXlfxxq18uWRNHNOGI24FwsySgfuB44DuwJlm1n2H2RYDFwCjd1i2MXALMBAYANxiZo3ilVVEBKBRZhqjRxxItxb1uPTpKbz25dJdLlOytYyzHv2cUx/4lGk1rEjEswcxAChw9/nuvhV4Hjg5egZ3X+ju04EdB1c5BnjP3Yvd/TvgPeDYOGYVEQEiZ0U9ffFA+rZuxK+e/5KRY2dTXh77WK27c/NrM5m9fD31M1K57pXpcb0JUlWLZ4HIBZZEvS4Mpu2zZc3sEjPLN7P8oqKiPQ4qIhKtQUYqz4wYyJkDWnP/uHlc8nQ+6zeX/mi+FyYv4eUphVx1RGdGDuvN7OXrebgGXYhXra+DcPdH3D3P3fNycmrPWQciEn9pKUn8+af7c9vJPRg3p4ifPjCBl/KXsGZTZJDAGYVr+b8xsxjSOZtfHdGZo7o344ReLbjvgwIKVq4POf2+Ec+zmJYC0QOitAqmVXbZQ3dY9sN9kkpEpJLMjPMGtaNTThbX/Xs61748nZQkY1DHJswv2kh2Zhr/OKMvyUmRK7f/8JMefFqwiutemcFLlw4iKal638Uunj2IyUBnM2tvZmnAGcCYSi47FjjazBoFB6ePDqaJiFS5gzpl89G1hzHmioMZMaQDi4s3sWrDFu4/+wAaZ6b9b76ceuncfEJ3piz6jicnLIy5rlUbtnDVc19Ui+E+4nqhnJkdD/wdSAaecPc/mdltQL67jzGz/sCrQCNgM7Dc3XsEy14E3BCs6k/u/q+KtqUL5USkqrg7m0vL/zek+I5tFz05mXFzirj80I5cc1SX/9029ZsV67noqcksKS4ht2EGH/z2ENJTfryOqqQrqUVEqtDm0jJufX0Wz01awoD2jbnvzL58s2IDlz87hfSUZC4e3J4735nNrSf14PyD2oWaVVdSi4hUoTqpyfzl1F70b9eYG1+dybF//4j1m7fRMSeLxy/II7dhBh/OWcl9HxQwPK8VddMS86u4Wp/FJCKSyE49oBVjrjiYFg0yOLRrDi9fPohWjepiZlx7TFdWbdjCUxMWVbiOmUvXcv+4Akq2llVR6u8lZtkSEakhOjerx1u/GvKj6XntGnNY1xweGj+Pswa2oUFG6g/aN5eWce/73/DwR/MpK3femvEtj5wX6X1UFfUgRERCcs3RXVlbUsrjH8//wfQpi77jhHs/5oEP53Fq31zuPbMvi1dv4qT7PmHSguIqy6cehIhISHrmNuCEXi147JMFrCkppWDlBgpWbmDl+i20bFCHpy4awCHB0OPdW9Tj56OmcNajn/PHU3pyxoA2cc+ns5hEREI0r2gDJ9z7MSlJSXRsmkWnnCz2a1GP0/u3pl6dH+52WltSypXPfRG5t/bZB3Dc/i32evs6zVVEJIFtLi0jPSUp5r20Y8175qOf8/W363j5soPomdtgr7ZdUYHQMQgRkZDVSU2uVHHYPu8j5+bRuG4aI57KZ8W6zXHLpQIhIlLN5NRL57Hz+7Nucyk/H5Uft1NgVSBERKqh7i3r848z+jJj6Vp++/I04nG4QGcxiYhUU0d1b8b1x3Zj49Yy3KGSe6kqTQVCRKQau/SQjnFbt3YxiYhITCoQIiISkwqEiIjEpAIhIiIxqUCIiEhMKhAiIhKTCoSIiMSkAiEiIjHVmNFczawIqPjefRXLBlbtozj7UqLmgsTNlqi5IHGzJWouSNxsiZoLdi9bW3fPidVQYwrE3jKz/J0NeRumRM0FiZstUXNB4mZL1FyQuNkSNRfsu2zaxSQiIjGpQIiISEwqEN97JOwAO5GouSBxsyVqLkjcbImaCxI3W6Lmgn2UTccgREQkJvUgREQkJhUIERGJqVYUCDN7wsxWmtnMqGkjzWy2mU03s1fNrGFU2+/NrMDM5pjZMSFkuz3I9aWZvWtmLYPpZmb3Btmmm9kBVZkrqu0aM3Mzy67qXDvLZmZ/MLOlwWf2pZkdH9VWJf+fO/vMzOzK4GdtlpndVdW5dpbNzF6I+rwWmtmXCZStj5l9HmTLN7MBwfRQfwfMrLeZfWZmM8zsdTOrH9VWVT9nrc1snJl9FfxM/SqY3tjM3jOzb4J/GwXT9/wzc/ca/wCGAgcAM6OmHQ2kBM/vBO4MnncHpgHpQHtgHpBcxdnqRz2/CngoeH488DZgwIHAxKrMFUxvDYwlclFidlXnquAz+wPw2xjzVtn/505yHQb8F0gPXjdNlJ+zHdrvBv4vUbIB7wLHRf18fVjVP2s7yTUZOCR4fhFwewg/Zy2AA4Ln9YC5wfbvAq4Ppl8f9Z22x59ZrehBuPtHQPEO0951923By8+BVsHzk4Hn3X2Luy8ACoABVZxtXdTLTGD7mQQnA6M84nOgoZm1qKpcgXuA30VlqtJcu8gWS5X9f+4k1+XAHe6+JZhnZVXnqiAbEPkLEzgNeC6Bsjmw/a/zBsCyqGxh/g50AT4Knr8H/CwqV1X9nH3r7lOD5+uBr4HcIMNTwWxPAadEZdujz6xWFIhKuIhIhYXIB70kqq0wmFalzOxPZrYEOBv4v0TIZmYnA0vdfdoOTQnxmQFXBF3oJ7Z3rwk/WxdgiJlNNLPxZtY/QXJFGwKscPdvgteJkO1qYGTwO/BX4PcJkm0WkS9cgOFEetSh5TKzdkBfYCLQzN2/DZqWA832NlutLxBmdiOwDXg27CzR3P1Gd29NJNcVYecxs7rADXxfrBLNg0BHoA/wLZFdJokgBWhMpGt/LfBi8Bd7IjmT73sPieJy4NfB78CvgcdDzrPdRcAvzGwKkd07W8MKYmZZwCvA1TvsdcAj+5b2+hqGWl0gzOwC4ETg7OADBVjK938VQGTX09IqjhbtWb7vxoaZrSORfavTzGxhsO2pZtY85FwAuPsKdy9z93LgUb7v3oedrRD4d9C9nwSUExlILexcAJhZCnAq8ELU5ETIdj7w7+D5SyTI/6e7z3b3o929H5GiOi+MXGaWSqQ4POvu2z+nFdt3HQX/bt+ducfZam2BMLNjiexLP8ndN0U1jQHOMLN0M2sPdAYmVXG2zlEvTwZmR2U7Lzgr4UBgbVSXMq7cfYa7N3X3du7ejsgX3wHuvjzMXNvtsE/1p8D2M0/C/v/8D5ED1ZhZFyCNyCibYefa7khgtrsXRk1LhGzLgEOC54cD23d/hfqzZmZNg3+TgJuAh6JyVclnFvRAHwe+dve/RTWNIVJYCf59LWr6nn1m8TjKnmgPIpX+W6CUyBfbxUQOIi0BvgweD0XNfyORvwzmEJxJUcXZXiHyBTcdeB3IDeY14P4g2wwgrypz7dC+kO/PYqqyXBV8Zk8H254e/EK0qOr/z53kSgOeCf4/pwKHJ8rPWTD9SeCyGPOH/TswGJhC5MygiUC/RPgdAH5F5KyhucAdBKNRVPHP2WAiu4+mR31/HQ80Ad4nUkz/CzTe289MQ22IiEhMtXYXk4iIVEwFQkREYlKBEBGRmFQgREQkJhUIERGJSQVCJERmdqiZvRF2DpFYVCBERCQmFQiRSjCzc8xsUnB/gofNLNnMNpjZPcGY/O+bWU4w7/Z7GWy/18j2cfk7mdl/zWyamU01s47B6rPM7GWL3DPi2e1jNZnZHcGY/9PN7K8hvXWpxVQgRHbBzPYDTgcOdvc+QBmRUXYzgXx37wGMB24JFhkFXOfuvYhcubp9+rPA/e7eGziIyFW6EBmN82oiY/p3AA42syZEhgzpEaznj/F9lyI/pgIhsmtHAP2AyRa569oRRL7Iy/l+kLtngMFm1gBo6O7jg+lPAUPNrB6RIVNeBXD3zf79GGCT3L3QIwMNfgm0A9YCm4HHzexUIHq8MJEqoQIhsmsGPOXufYJHV3f/Q4z59nTcmi1Rz8uI3OlwG5ERTF8mMuLwO3u4bpE9pgIhsmvvA8OiRvJsbGZtifz+DAvmOQv4xN3XAt+Z2ZBg+rnAeI/c+avQzE4J1pEe3GMjpmCs/wbu/haR+yH0jscbE6lIStgBRBKdu39lZjcB7wbDPJcCvwQ2AgOCtpVEjlNAZKjlh4ICMB+4MJh+LvCwmd0WrGN4BZutB7xmZnWI9GB+s4/flsguaTRXkT1kZhvcPSvsHCLxol1MIiISk3oQIiISk3oQIiISkwqEiIjEpAIhIiIxqUCIiEhMKhAiIhLT/wNsTDfFQa9XTgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}