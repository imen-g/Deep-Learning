{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MULTICLASS_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8JwBZ4sjv/wItEv90dc+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imen-g/Deep-Learning/blob/master/MULTICLASS_classification_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjDZqn1BFBP"
      },
      "source": [
        "\n",
        "\n",
        "**Importing libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXgbzyFYAlav"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vb9-l5IBRah"
      },
      "source": [
        "**Importing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "5voQddgVFCgm",
        "outputId": "b6ae45f8-c769-4b49-ef14-eaded93f8505"
      },
      "source": [
        "data = pd.read_csv('iris.csv',parse_dates=True) \n",
        "data.sample(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>6.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
              "122           7.7          2.8           6.7          2.0   Virginica\n",
              "87            6.3          2.3           4.4          1.3  Versicolor\n",
              "56            6.3          3.3           4.7          1.6  Versicolor\n",
              "146           6.3          2.5           5.0          1.9   Virginica\n",
              "133           6.3          2.8           5.1          1.5   Virginica"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6n6-iKYGmQP"
      },
      "source": [
        "**Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HED8GZjqGlrv",
        "outputId": "3a944b05-e721-41c3-d2a4-7fdd5a5150a7"
      },
      "source": [
        "data.isna().sum() #Checking for missing values"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal.length    0\n",
              "sepal.width     0\n",
              "petal.length    0\n",
              "petal.width     0\n",
              "variety         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfvwFsSCF4ib",
        "outputId": "11213fd4-989f-4dd1-9800-d8daeee2e885"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dszaHogZgkgS",
        "outputId": "5f59f59e-a0fe-4bf1-d6b0-bde46d208ecd"
      },
      "source": [
        "data.variety.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Versicolor    50\n",
              "Setosa        50\n",
              "Virginica     50\n",
              "Name: variety, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "rxOvIe62F9Jx",
        "outputId": "0ffbb7dc-af72-476a-80b2-aced798125d8"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal.length  sepal.width  petal.length  petal.width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.057333      3.758000     1.199333\n",
              "std        0.828066     0.435866      1.765298     0.762238\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXcNxiqGHwnp"
      },
      "source": [
        "For better performance of our model we need to keep numerical values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM1WKP8UHgEE",
        "outputId": "4ad3d200-475c-4b15-cafc-9a5166f60cc9"
      },
      "source": [
        "data.max() #displays the max of every column"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal.length          7.9\n",
              "sepal.width           4.4\n",
              "petal.length          6.9\n",
              "petal.width           2.5\n",
              "variety         Virginica\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F09rU5YBH8OW"
      },
      "source": [
        "data['sepal.length'] = data['sepal.length']/7.9\n",
        "data['sepal.width'] = data['sepal.width']/4.4\n",
        "data['petal.length'] = data['petal.length']/6.9\n",
        "data['petal.width'] = data['petal.width']/2.5\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "jmsbuarTJ-kx",
        "outputId": "1387d84d-7d36-463b-9b54-b2394dde0ce6"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.683544</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.60</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.708861</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.710145</td>\n",
              "      <td>0.80</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.734177</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.579710</td>\n",
              "      <td>0.48</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.974684</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.80</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>0.734177</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.40</td>\n",
              "      <td>Versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
              "84       0.683544     0.681818      0.652174         0.60  Versicolor\n",
              "121      0.708861     0.636364      0.710145         0.80   Virginica\n",
              "92       0.734177     0.590909      0.579710         0.48  Versicolor\n",
              "122      0.974684     0.636364      0.971014         0.80   Virginica\n",
              "67       0.734177     0.613636      0.594203         0.40  Versicolor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kovNhYdPafQ8"
      },
      "source": [
        "**Model creation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9WSecMOoOVl"
      },
      "source": [
        "data = data.values\n",
        "X = data[:,0:4].astype(float)\n",
        "Y = data[:,4]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysN0AIRvoy6f",
        "outputId": "310b49c7-a671-4e35-87eb-27359d13c68e"
      },
      "source": [
        "X"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.64556962, 0.79545455, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.68181818, 0.20289855, 0.08      ],\n",
              "       [0.59493671, 0.72727273, 0.1884058 , 0.08      ],\n",
              "       [0.58227848, 0.70454545, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.81818182, 0.20289855, 0.08      ],\n",
              "       [0.6835443 , 0.88636364, 0.24637681, 0.16      ],\n",
              "       [0.58227848, 0.77272727, 0.20289855, 0.12      ],\n",
              "       [0.63291139, 0.77272727, 0.2173913 , 0.08      ],\n",
              "       [0.55696203, 0.65909091, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.70454545, 0.2173913 , 0.04      ],\n",
              "       [0.6835443 , 0.84090909, 0.2173913 , 0.08      ],\n",
              "       [0.60759494, 0.77272727, 0.23188406, 0.08      ],\n",
              "       [0.60759494, 0.68181818, 0.20289855, 0.04      ],\n",
              "       [0.5443038 , 0.68181818, 0.15942029, 0.04      ],\n",
              "       [0.73417722, 0.90909091, 0.17391304, 0.08      ],\n",
              "       [0.72151899, 1.        , 0.2173913 , 0.16      ],\n",
              "       [0.6835443 , 0.88636364, 0.1884058 , 0.16      ],\n",
              "       [0.64556962, 0.79545455, 0.20289855, 0.12      ],\n",
              "       [0.72151899, 0.86363636, 0.24637681, 0.12      ],\n",
              "       [0.64556962, 0.86363636, 0.2173913 , 0.12      ],\n",
              "       [0.6835443 , 0.77272727, 0.24637681, 0.08      ],\n",
              "       [0.64556962, 0.84090909, 0.2173913 , 0.16      ],\n",
              "       [0.58227848, 0.81818182, 0.14492754, 0.08      ],\n",
              "       [0.64556962, 0.75      , 0.24637681, 0.2       ],\n",
              "       [0.60759494, 0.77272727, 0.27536232, 0.08      ],\n",
              "       [0.63291139, 0.68181818, 0.23188406, 0.08      ],\n",
              "       [0.63291139, 0.77272727, 0.23188406, 0.16      ],\n",
              "       [0.65822785, 0.79545455, 0.2173913 , 0.08      ],\n",
              "       [0.65822785, 0.77272727, 0.20289855, 0.08      ],\n",
              "       [0.59493671, 0.72727273, 0.23188406, 0.08      ],\n",
              "       [0.60759494, 0.70454545, 0.23188406, 0.08      ],\n",
              "       [0.6835443 , 0.77272727, 0.2173913 , 0.16      ],\n",
              "       [0.65822785, 0.93181818, 0.2173913 , 0.04      ],\n",
              "       [0.69620253, 0.95454545, 0.20289855, 0.08      ],\n",
              "       [0.62025316, 0.70454545, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.72727273, 0.17391304, 0.08      ],\n",
              "       [0.69620253, 0.79545455, 0.1884058 , 0.08      ],\n",
              "       [0.62025316, 0.81818182, 0.20289855, 0.04      ],\n",
              "       [0.55696203, 0.68181818, 0.1884058 , 0.08      ],\n",
              "       [0.64556962, 0.77272727, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.79545455, 0.1884058 , 0.12      ],\n",
              "       [0.56962025, 0.52272727, 0.1884058 , 0.12      ],\n",
              "       [0.55696203, 0.72727273, 0.1884058 , 0.08      ],\n",
              "       [0.63291139, 0.79545455, 0.23188406, 0.24      ],\n",
              "       [0.64556962, 0.86363636, 0.27536232, 0.16      ],\n",
              "       [0.60759494, 0.68181818, 0.20289855, 0.12      ],\n",
              "       [0.64556962, 0.86363636, 0.23188406, 0.08      ],\n",
              "       [0.58227848, 0.72727273, 0.20289855, 0.08      ],\n",
              "       [0.67088608, 0.84090909, 0.2173913 , 0.08      ],\n",
              "       [0.63291139, 0.75      , 0.20289855, 0.08      ],\n",
              "       [0.88607595, 0.72727273, 0.68115942, 0.56      ],\n",
              "       [0.81012658, 0.72727273, 0.65217391, 0.6       ],\n",
              "       [0.87341772, 0.70454545, 0.71014493, 0.6       ],\n",
              "       [0.69620253, 0.52272727, 0.57971014, 0.52      ],\n",
              "       [0.82278481, 0.63636364, 0.66666667, 0.6       ],\n",
              "       [0.72151899, 0.63636364, 0.65217391, 0.52      ],\n",
              "       [0.79746835, 0.75      , 0.68115942, 0.64      ],\n",
              "       [0.62025316, 0.54545455, 0.47826087, 0.4       ],\n",
              "       [0.83544304, 0.65909091, 0.66666667, 0.52      ],\n",
              "       [0.65822785, 0.61363636, 0.56521739, 0.56      ],\n",
              "       [0.63291139, 0.45454545, 0.50724638, 0.4       ],\n",
              "       [0.74683544, 0.68181818, 0.60869565, 0.6       ],\n",
              "       [0.75949367, 0.5       , 0.57971014, 0.4       ],\n",
              "       [0.7721519 , 0.65909091, 0.68115942, 0.56      ],\n",
              "       [0.70886076, 0.65909091, 0.52173913, 0.52      ],\n",
              "       [0.84810127, 0.70454545, 0.63768116, 0.56      ],\n",
              "       [0.70886076, 0.68181818, 0.65217391, 0.6       ],\n",
              "       [0.73417722, 0.61363636, 0.5942029 , 0.4       ],\n",
              "       [0.78481013, 0.5       , 0.65217391, 0.6       ],\n",
              "       [0.70886076, 0.56818182, 0.56521739, 0.44      ],\n",
              "       [0.74683544, 0.72727273, 0.69565217, 0.72      ],\n",
              "       [0.7721519 , 0.63636364, 0.57971014, 0.52      ],\n",
              "       [0.79746835, 0.56818182, 0.71014493, 0.6       ],\n",
              "       [0.7721519 , 0.63636364, 0.68115942, 0.48      ],\n",
              "       [0.81012658, 0.65909091, 0.62318841, 0.52      ],\n",
              "       [0.83544304, 0.68181818, 0.63768116, 0.56      ],\n",
              "       [0.86075949, 0.63636364, 0.69565217, 0.56      ],\n",
              "       [0.84810127, 0.68181818, 0.72463768, 0.68      ],\n",
              "       [0.75949367, 0.65909091, 0.65217391, 0.6       ],\n",
              "       [0.72151899, 0.59090909, 0.50724638, 0.4       ],\n",
              "       [0.69620253, 0.54545455, 0.55072464, 0.44      ],\n",
              "       [0.69620253, 0.54545455, 0.53623188, 0.4       ],\n",
              "       [0.73417722, 0.61363636, 0.56521739, 0.48      ],\n",
              "       [0.75949367, 0.61363636, 0.73913043, 0.64      ],\n",
              "       [0.6835443 , 0.68181818, 0.65217391, 0.6       ],\n",
              "       [0.75949367, 0.77272727, 0.65217391, 0.64      ],\n",
              "       [0.84810127, 0.70454545, 0.68115942, 0.6       ],\n",
              "       [0.79746835, 0.52272727, 0.63768116, 0.52      ],\n",
              "       [0.70886076, 0.68181818, 0.5942029 , 0.52      ],\n",
              "       [0.69620253, 0.56818182, 0.57971014, 0.52      ],\n",
              "       [0.69620253, 0.59090909, 0.63768116, 0.48      ],\n",
              "       [0.7721519 , 0.68181818, 0.66666667, 0.56      ],\n",
              "       [0.73417722, 0.59090909, 0.57971014, 0.48      ],\n",
              "       [0.63291139, 0.52272727, 0.47826087, 0.4       ],\n",
              "       [0.70886076, 0.61363636, 0.60869565, 0.52      ],\n",
              "       [0.72151899, 0.68181818, 0.60869565, 0.48      ],\n",
              "       [0.72151899, 0.65909091, 0.60869565, 0.52      ],\n",
              "       [0.78481013, 0.65909091, 0.62318841, 0.52      ],\n",
              "       [0.64556962, 0.56818182, 0.43478261, 0.44      ],\n",
              "       [0.72151899, 0.63636364, 0.5942029 , 0.52      ],\n",
              "       [0.79746835, 0.75      , 0.86956522, 1.        ],\n",
              "       [0.73417722, 0.61363636, 0.73913043, 0.76      ],\n",
              "       [0.89873418, 0.68181818, 0.85507246, 0.84      ],\n",
              "       [0.79746835, 0.65909091, 0.8115942 , 0.72      ],\n",
              "       [0.82278481, 0.68181818, 0.84057971, 0.88      ],\n",
              "       [0.96202532, 0.68181818, 0.95652174, 0.84      ],\n",
              "       [0.62025316, 0.56818182, 0.65217391, 0.68      ],\n",
              "       [0.92405063, 0.65909091, 0.91304348, 0.72      ],\n",
              "       [0.84810127, 0.56818182, 0.84057971, 0.72      ],\n",
              "       [0.91139241, 0.81818182, 0.88405797, 1.        ],\n",
              "       [0.82278481, 0.72727273, 0.73913043, 0.8       ],\n",
              "       [0.81012658, 0.61363636, 0.76811594, 0.76      ],\n",
              "       [0.86075949, 0.68181818, 0.79710145, 0.84      ],\n",
              "       [0.72151899, 0.56818182, 0.72463768, 0.8       ],\n",
              "       [0.73417722, 0.63636364, 0.73913043, 0.96      ],\n",
              "       [0.81012658, 0.72727273, 0.76811594, 0.92      ],\n",
              "       [0.82278481, 0.68181818, 0.79710145, 0.72      ],\n",
              "       [0.97468354, 0.86363636, 0.97101449, 0.88      ],\n",
              "       [0.97468354, 0.59090909, 1.        , 0.92      ],\n",
              "       [0.75949367, 0.5       , 0.72463768, 0.6       ],\n",
              "       [0.87341772, 0.72727273, 0.82608696, 0.92      ],\n",
              "       [0.70886076, 0.63636364, 0.71014493, 0.8       ],\n",
              "       [0.97468354, 0.63636364, 0.97101449, 0.8       ],\n",
              "       [0.79746835, 0.61363636, 0.71014493, 0.72      ],\n",
              "       [0.84810127, 0.75      , 0.82608696, 0.84      ],\n",
              "       [0.91139241, 0.72727273, 0.86956522, 0.72      ],\n",
              "       [0.78481013, 0.63636364, 0.69565217, 0.72      ],\n",
              "       [0.7721519 , 0.68181818, 0.71014493, 0.72      ],\n",
              "       [0.81012658, 0.63636364, 0.8115942 , 0.84      ],\n",
              "       [0.91139241, 0.68181818, 0.84057971, 0.64      ],\n",
              "       [0.93670886, 0.63636364, 0.88405797, 0.76      ],\n",
              "       [1.        , 0.86363636, 0.92753623, 0.8       ],\n",
              "       [0.81012658, 0.63636364, 0.8115942 , 0.88      ],\n",
              "       [0.79746835, 0.63636364, 0.73913043, 0.6       ],\n",
              "       [0.7721519 , 0.59090909, 0.8115942 , 0.56      ],\n",
              "       [0.97468354, 0.68181818, 0.88405797, 0.92      ],\n",
              "       [0.79746835, 0.77272727, 0.8115942 , 0.96      ],\n",
              "       [0.81012658, 0.70454545, 0.79710145, 0.72      ],\n",
              "       [0.75949367, 0.68181818, 0.69565217, 0.72      ],\n",
              "       [0.87341772, 0.70454545, 0.7826087 , 0.84      ],\n",
              "       [0.84810127, 0.70454545, 0.8115942 , 0.96      ],\n",
              "       [0.87341772, 0.70454545, 0.73913043, 0.92      ],\n",
              "       [0.73417722, 0.61363636, 0.73913043, 0.76      ],\n",
              "       [0.86075949, 0.72727273, 0.85507246, 0.92      ],\n",
              "       [0.84810127, 0.75      , 0.82608696, 1.        ],\n",
              "       [0.84810127, 0.68181818, 0.75362319, 0.92      ],\n",
              "       [0.79746835, 0.56818182, 0.72463768, 0.76      ],\n",
              "       [0.82278481, 0.68181818, 0.75362319, 0.8       ],\n",
              "       [0.78481013, 0.77272727, 0.7826087 , 0.92      ],\n",
              "       [0.74683544, 0.68181818, 0.73913043, 0.72      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUyIADYUpTPF",
        "outputId": "3ff0ec8a-9a26-440c-a39d-2c8be2bd6d46"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
              "       'Setosa', 'Setosa', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
              "       'Versicolor', 'Versicolor', 'Versicolor', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
              "       'Virginica', 'Virginica', 'Virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFz7fGJuX67"
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables \n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6MjFXgVUgZa",
        "outputId": "af1ccc72-db54-4ca5-8c2d-edb8487173d4"
      },
      "source": [
        "dummy_y"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJKPzFNSrCA"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor=\"accuracy\")\n",
        "early_stopping = EarlyStopping(monitor=\"accuracy\", patience=10, min_delta=10000)\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"accuracy\", factor=0.5, patience=10, min_delta=100000)\n",
        "#tensorboard = TensorBoard(\"logs\") #W&B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdDgwwaDzybA"
      },
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu', kernel_regularizer='l1', bias_regularizer='l2', activity_regularizer='l1_l2'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6NGvR8Q8t-x",
        "outputId": "bce3aa56-9304-4812-d915-8d5968ae4c03"
      },
      "source": [
        "hist = baseline_model().fit(X, dummy_y, batch_size=5, epochs=100, verbose=2,callbacks=[checkpoint, early_stopping, reduce_lr])\n",
        "                 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 - 0s - loss: 1.2072 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "30/30 - 0s - loss: 1.1942 - accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "30/30 - 0s - loss: 1.1838 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "30/30 - 0s - loss: 1.1729 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "30/30 - 0s - loss: 1.1631 - accuracy: 0.3400\n",
            "Epoch 6/100\n",
            "30/30 - 0s - loss: 1.1536 - accuracy: 0.2133\n",
            "Epoch 7/100\n",
            "30/30 - 0s - loss: 1.1440 - accuracy: 0.4600\n",
            "Epoch 8/100\n",
            "30/30 - 0s - loss: 1.1348 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "30/30 - 0s - loss: 1.1262 - accuracy: 0.5400\n",
            "Epoch 10/100\n",
            "30/30 - 0s - loss: 1.1176 - accuracy: 0.6333\n",
            "Epoch 11/100\n",
            "30/30 - 0s - loss: 1.1082 - accuracy: 0.8133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2J4PvOS14K2"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-LOyxbAlTNs"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTdHmLcxvPo8",
        "outputId": "c52947f7-67a5-49f4-be2e-8bd9035a0fbf"
      },
      "source": [
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc965c78730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc969ad0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc968efa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc968c01950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc965594598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc968b3d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc9662d8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc968f41b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc9691f4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc9632470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9600000023841858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBn6fw0e9l-N"
      },
      "source": [
        "losses = hist.history['loss']\n",
        "epochs = hist.epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KsAOOFil92ml",
        "outputId": "750d8312-87ba-4d98-c0de-cc029bab2bd6"
      },
      "source": [
        "plt.plot(epochs, losses)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel('losses')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5QUddr28e89gTDkMAKSkawShxwGBQQVZTFiwASKkeiuq+uuG3Tf3RURDICIoihGzBGBBQYQkCGIBMlZESRJjvf7xzTvMy/PAANMT/V0X59z5thT1V191VH7mqrq+v3M3RERETlRXNABREQkMqkgREQkSyoIERHJkgpCRESypIIQEZEsqSBERCRLKgiRGGdma82sQ9A5JPKoICRPitYPNTObYmYHzGxPpp/Pgs4lsSkh6AAiscrM4t39aBarHnT3UbkeSOQEOoKQqGJm+c1siJn9FPoZYmb5Q+tKm9nnZrbTzLab2TQziwute8TMNpnZbjNbZmbtT7L918xshJlNCD13qplVzrS+dmjd9tB2bjjhtcPN7Esz2wtccob71s7MNprZY2b2a+go6pZM64uZ2Rgz22pm68zs8eP7F1p/t5ktDeVeYmaNMm2+gZktNLNdZvaumRU4k2wSnVQQEm3+BDQHGgD1gabA46F1A4GNQDJQBngMcDOrBTwINHH3IkAnYO0p3uMW4B9AaWABMBbAzAoBE4C3gPOA7sAwM6ub6bU3A08BRYDpZ7F/ZUPvWx64HRgZyg/wPFAMqAakArcBd4ayXQ/8NbSsKHA1sC3Tdm8AOgNVgXrAHWeRTaKMCkKizS3A3919i7tvBf4G9AitOwyUAyq7+2F3n+YZg5EdBfIDdc0s0d3XuvuqU7zHF+6e5u4HySikFmZWEegCrHX30e5+xN3nAx8A12d67SfuPsPdj7n7gZNs/7nQUc7xn3+csP7P7n7Q3acCXwA3mFk8GYX0qLvvdve1wDOZ9r0X8B93n+MZVrr7uszv6e4/uft24DMyClZinApCos35QOYPvnWhZQBPAyuBb8xstZn9EcDdVwL9yPgLe4uZvWNm53NyG44/cPc9wPbQe1QGmmX+cCejsMpm9dpT6OPuxTP9/DnTuh3uvjeL/SsNJGax7+VDjysCpyq9zZke7wMKZyOnRDkVhESbn8j4oD6uUmgZob+sB7p7NTJOsQw4fq3B3d9y99ah1zrw71O8R8XjD8ysMFAy9B4bgKknfLgXdvf7Mr32XIdPLhE6lXXi/v1KxhHSifu+KfR4A3DBOb63xBgVhORliWZWINNPAvA28LiZJZtZaeAvwJsAZtbFzKqbmQG7yDi1dMzMapnZpaGL2QeA/cCxU7zvFWbW2szykXEtYpa7bwA+B2qaWQ8zSwz9NDGzOjm8338zs3xm1oaM01rvh74N9R7wlJkVCV04H3B834FRwMNm1tgyVM98cV0kKyoIycu+JOPD/PjPX4EngXRgIfADMC+0DKAGMBHYA8wEhrn7ZDKuP/yLjL/CN5NxgfnRU7zvW8ATZJxaagzcChlHKMBlZFwL+Cm0rX+Htn8mXjjhPoi5mdZtBnaEtj8WuNfdfwytewjYC6wm4wL4W8CroWzvk3Fx/C1gN/AxGUc+IidlmjBIJPvM7DVgo7s/frrnhuG92wFvunuF3H5viU06ghARkSypIEREJEs6xSQiIlnSEYSIiGQpqgbrK126tFepUiXoGCIiecbcuXN/dffkrNZFVUFUqVKF9PT0oGOIiOQZZrbuZOt0iklERLKkghARkSypIEREJEsqCBERyZIKQkREsqSCEBGRLKkgREQkSyoI4PlJK1j8066gY4iIRJSYL4gdew/x1nfruX7ETCYt/SXoOCIiESPmC6JEoXx88kArLkguzN1j0hk9Y03QkUREIkLMFwTAeUUL8G7v5nSoU4a/fbaEJz5ZxJGjp5pxUkQk+qkgQpLyJTD81sbc3aYqr89cR68x6ew+cDjoWCIigVFBZBIfZ/zpyro81e0ipq34letHzOSnnfuDjiUiEggVRBZuaVaZ0Xc0YdOO/XR9cQYLN+4MOpKISK5TQZxE25rJjLuvJfni47jhpZmMX7w56EgiIrlKBXEKtcoW4eMHWlG7bFHufXMuL6etRlO0ikisUEGcRnKR/LxzT3Muv6gsT325lD99vIjD+oaTiMQAFUQ2FEiM54WbGnFfuwt4a/Z67nptDr/pG04iEuVUENkUF2c80rk2/7m2HjNXbeO64d+yYfu+oGOJiIRN2ArCzF41sy1mtugk628xs4Vm9oOZfWtm9TOt62xmy8xspZn9MVwZz8YNTSoy5q6mbN51gG7DZjB//Y6gI4mIhEU4jyBeAzqfYv0aINXdLwb+AYwEMLN44EXgcqAucJOZ1Q1jzjPWsnppPry/FUn5Eug+chZf/vBz0JFERHJc2ArC3dOA7adY/627H//zexZQIfS4KbDS3Ve7+yHgHaBruHKerernFeaj+1tyUfli3D92HsOmrNQ3nEQkqkTKNYiewFehx+WBDZnWbQwtizilCudnbK9mXF3/fP7z9TIe+WAhh47oG04iEh0Sgg5gZpeQURCtz/L19wD3AFSqVCkHk2VPgcR4hnZvQJXShXhu0go2bN/PiFsbUywpMdeziIjkpECPIMysHjAK6Oru20KLNwEVMz2tQmhZltx9pLunuHtKcnJy+MKegpkxoGNNBt9Qn/R12+k2fAbrtu0NJIuISE4JrCDMrBLwIdDD3ZdnWjUHqGFmVc0sH9Ad+DSIjGfqmkYVeLNnM7bvPUS3Yd+Svvakl2BERCJeOL/m+jYwE6hlZhvNrKeZ3Wtm94ae8hegFDDMzBaYWTqAux8BHgTGA0uB99x9cbhy5rRm1Urx0f2tKFYwkZtfns0nC0568CMiEtEsmr55k5KS4unp6UHHADKmMu395ly+W7OdAR1r8tCl1TGzoGOJiPx/zGyuu6dktS5SvsUUdUoUyscbPZtyTcPyDJ6wnIHvfc/BI0eDjiUikm2Bf4spmuVPiOeZG+pTtXQhnpmwnI079/PSrY0pUShf0NFERE5LRxBhZmY81L4GQ7s3YMGGnXQbNoPVW/cEHUtE5LRUELmka4PyvH13M347cIRrhn/L7NXbTv8iEZEAqSByUePKJfno/paUKpSPW1+ZzQdzNwYdSUTkpFQQuaxyqUJ8eF8rmlQpycD3v+fp8T9yRBMQiUgEUkEEoFhSIq/f1ZTuTSry4uRVXDdiJqt0XUJEIowKIiCJ8XH869p6PHdTQ9b8upcrn5vG6BlrOHYseu5LEZG8TQURsKvrn883/dvSvFop/vbZEm4ZNZuNOzRTnYgETwURAcoULcDoO5rwr2suZuHGnXQeMo330jdofgkRCZQKIkKYGd2bVuLrfm258Pyi/GHcQu4ek86W3QeCjiYiMUoFEWEqlkzi7bub8/iVdUhb8Sudnk3ji4Wa0lREcp8KIgLFxRm92lTjyz6tqVQyiQfemkeft+ezc9+hoKOJSAxRQUSw6ucV4YP7WjKgY02+/OFnLns2jcnLtgQdS0RihAoiwiXEx9GnfQ0+fqAVxZMSuXP0HB79cCF7Dh4JOpqIRDkVRB5xUflifPZQa3qnVuOdORu4fGiaxnMSkbBSQeQh+RPiefTyOrzXuwWG0f3lWTz5+RIOHNY8EyKS81QQeVCTKiX5qm8bbmlWiVHT19Dl+eks3Lgz6FgiEmVUEHlUofwJPPm7ixlzV1P2HDhCt2HfMnjCcg5r4D8RySEqiDyubc1kxvdrS9f65/PcpBV0GzaD5b/sDjqWiEQBFUQUKJaUyOAbGzDi1kb8vPMAXZ6fzsi0VRzVwH8icg5UEFGk80XlGN+/Le1qJvPPL3+k+8iZrN+mgf9E5OyoIKJM6cL5ealHYwbfUJ8fN++m89A0xs5ep4H/ROSMqSCikJlxTaMKjO/XlsaVS/CnjxZx++g5bN6lgf9EJPtUEFHs/OIFGXNXU/7R9ULmrNnOZc9O5eP5m3Q0ISLZooKIcmZGjxZV+KpvG2qUKUK/dxdw/9h5bNtzMOhoIhLhVBAxokrpQrzXuwWPdK7NpKVb6DQkjUlLfwk6lohEMBVEDImPM+5rdwGfPtSK5CIF6Pl6On/+eBH7D2moDhH531QQMah22aJ8/EBL7m5TlTdmreOqF6az+KddQccSkQijgohR+RPi+dOVdXmjZ1N+23+Ybi9+y6hpqzmmm+tEJEQFEePa1Ejm635tSa2VzJNfLOX20d/xy2/6OqyIhLEgzOxVM9tiZotOsr62mc00s4Nm9vAJ6/qb2WIzW2Rmb5tZgXDlFChZKB8jezTmn90uZs7a7XQeksb4xZuDjiUiAQvnEcRrQOdTrN8O9AEGZV5oZuVDy1Pc/SIgHugepowSYmbc3KwSnz/UhvIlCtL7jbk8+uEP7DukmetEYlXYCsLd08gogZOt3+Luc4DDWaxOAAqaWQKQBPwUnpRyournFebD+1qFZq5bT5fnp7Noky5gi8SiiLsG4e6byDiqWA/8DOxy92+CTRVb8iXE8ejldRjbsxn7Dh6l27AZjJi6ShewRWJMxBWEmZUAugJVgfOBQmZ26ymef4+ZpZtZ+tatW3MrZkxoWb00X/drQ4c6ZfjXVz9y6yuz+XnX/qBjiUguibiCADoAa9x9q7sfBj4EWp7sye4+0t1T3D0lOTk510LGiuJJ+Rh2SyP+c209FmzYSech0/jqh5+DjiUiuSASC2I90NzMkszMgPbA0oAzxTQz44YmFfmiTxuqlErivrHzeGTcQvYe1AVskWiWEK4Nm9nbQDugtJltBJ4AEgHcfYSZlQXSgaLAMTPrB9R199lmNg6YBxwB5gMjw5VTsq9q6UKMu68lQyYuZ9iUVcxes42h3RtSv2LxoKOJSBhYNA39nJKS4unp6UHHiAmzVm9jwLsL2LL7IP071uTe1AuIj7OgY4nIGTKzue6ektW6SDzFJHlA82ql+KpvWzpdVJanxy/jppdnsWmnLmCLRBMVhJy1YkmJvHBTQwZdX5/Fm3Zx+ZA0Pl+oW1ZEooUKQs6JmXFd4wp82bcN1ZIL8+Bb8xn43vfs0QVskTxPBSE5onKpQrx/bwv6XFqdj+Zv5Iqh05i3fkfQsUTkHKggJMckxscx4LJavNu7BUePOdePmMlzk1Zw5OixoKOJyFlQQUiOa1KlJF/1a0OXeuUYPGE53UfOYsP2fUHHEpEzpIKQsChaIJGh3Rsy5MYG/Lh5N1cMncYnCzYFHUtEzoAKQsLqdw3L81XfNtQsW4S+7yyg3zvz+e1AVgP4ikikUUFI2FUsmcS79zSnf4eafLbwZy4fMo3Jy7YEHUtETkMFIbkiIT6Ovh1q8P69LSiQGMedo+fQ/90FbN97KOhoInISKgjJVY0qleDLvm3oc2l1Pvv+JzoOnsqn3/9ENA35IhItVBCS6/InxDPgslp89lBrKpQoSJ+359Pr9XTNNSESYVQQEpg65Yry4f2tePzKOsxY9SsdB6fx5qx1mrlOJEKoICRQ8XFGrzbV+KZfKvUqFOPxjxfR/eVZrN66J+hoIjFPBSERoVKpJMb2asZ/rq3H0p9/o/PQaQybspLDugtbJDAqCIkYx2eumzQglUtrncd/vl5G1xdmsGjTrqCjicQkFYREnPOKFmBEj8aMuLURW/ccpOuLM/jXVz9y4PDRoKOJxBQVhESszheVY2L/VK5tVJ4RU1dx+dBpzFq9LehYIjFDBSERrVhSIv+5rj5jezXj6DGn+8hZPPbRDxquQyQXqCAkT2hVvTRf92tDr9ZVeee79Vw2OI0JS34JOpZIVFNBSJ6RlC+Bx7vU5aP7W1E8KZG7x6Tz4Fvz+HXPwaCjiUQlFYTkOfUrFufTB1szoGNNvln8Cx0GT+XDeRs1XIdIDlNBSJ6ULyGOPu1r8EWf1lyQXJgB733P7aPnsHGHJiYSySkqCMnTapQpwvu9W/C3qy8kfe12Lns2jddmrOGohusQOWcqCMnz4uKM21tW4Zv+bWlSpSR//WwJ14/4lhW/7A46mkiepoKQqFGhRBKv3dmEZ2+sz+pf93Llc9MZOnEFh45ouA6Rs3HGBWFmJcysXjjCiJwrM6NbwwpMHJBKp4vK8uzE5Vz1/HQWbNgZdDSRPCdbBWFmU8ysqJmVBOYBL5vZ4PBGEzl7pQvn5/mbGjLqthR27T/MNcNm8I/Pl7Dv0JGgo4nkGdk9gijm7r8B1wBj3L0Z0CF8sURyRoe6ZfhmQFtualqJV6avoePgNCYt1Q12ItmR3YJIMLNywA3A52HMI5LjihZI5KluF/P+vS0olD+enq+nc+8bc9m860DQ0UQiWnYL4u/AeGCVu88xs2rAivDFEsl5TaqU5POH2vD7TrWYvGwLHQZPZbS+EityUtkqCHd/393ruft9od9Xu/u1p3qNmb1qZlvMbNFJ1tc2s5lmdtDMHj5hXXEzG2dmP5rZUjNrkd0dEjmVfAlxPHBJdSb0T6VR5RL87bMldBumOSdEspLdi9Q1zWzS8Q97M6tnZo+f5mWvAZ1PsX470AcYlMW6ocDX7l4bqA8szU5OkeyqVCqJ1+9swvM3NeTnXQe4+oXp/P2zJew5qIvYIsdl9xTTy8CjwGEAd18IdD/VC9w9jYwSONn6Le4+5/g2jzOzYkBb4JXQ8w65u76jKDnOzLiq/vlMHJDKzc0qMfrbNXQcPJXxizcHHU0kImS3IJLc/bsTloXrT62qwFZgtJnNN7NRZlYoTO8lQrGCiTz5u4v54L6WFCuYSO835tLr9XQ27dwfdDSRQGW3IH41swsABzCz64Cfw5QpAWgEDHf3hsBe4I8ne7KZ3WNm6WaWvnXr1jBFkljQqFIJPnuoNY9dUZsZK3+l4+CpjJq2miNHdSe2xKbsFsQDwEtAbTPbBPQD7gtTpo3ARnefHfp9HBmFkSV3H+nuKe6ekpycHKZIEisS4+O4p+0FTBjQlubVSvHkF0u5+oUZuhNbYlJ2v8W02t07AMlAbXdv7e5rwxHI3TcDG8ysVmhRe2BJON5L5GQqlEjildtTGH5LI7btPUi3YTP4yyeLNNWpxBTLziQrZtYXGA3sJuOCdSPgj+7+zSle8zbQDigN/AI8ASQCuPsIMysLpANFgWPAHqCuu/9mZg2AUUA+YDVwp7vvOF3OlJQUT09PP+3+iJyJ3QcO88w3y3l95lqSC+fniasu5IqLy2JmQUcTOWdmNtfdU7Jcl82C+N7d65tZJ+Be4HHgDXc/6amfIKggJJwWbtzJYx/9wKJNv3FJrWT+3vUiKpZMCjqWyDk5VUFk9xrE8T+VriBjLKbFmZaJxIR6FYrz8f2t+HOXuny3Zjsdn53K8CmrOKyL2BKlslsQc83sGzIKYryZFSHjtJBITEmIj6Nn66pMHJhKas1k/v31j3R5bjpz1530lh+RPCu7BdGTjK+aNnH3fWRcS7gzbKlEIly5YgV5qUcKL9+Wwu4Dh7l2+Ewe/fAHdu3TRWyJHtktiBbAMnffaWa3knENQoPXSMzrWLcMEwak0qt1Vd5L30D7wVP4ZMEmsnNtTyTSZbcghgP7zKw+MBBYBYwJWyqRPKRQ/gQe71KXTx9sRfkSSfR9ZwG3vfoda3/dG3Q0kXOS3YI44hl/EnUFXnD3F4Ei4YslkvdceH4xPryvJX/veiEL1u/ksiFpvPBfzYkteVd2C2K3mT0K9AC+MLM4Qvc0iMj/iI8zbmtRhYkDU+lYpwyDvlnOFc9N47s1uogteU92C+JG4CBwV+hO5wrA02FLJZLHlSlagBdvacToO5pw4PBRbnhpJn/8YKEuYkuekq0b5QDMrAzQJPTrd+6+JWypzpJulJNItO/QEYZOXMGo6WsokZTIX666kKvqldOd2BIRzvlGOTO7AfgOuJ6Mealnh0Z0FZHTSMqXwKNX1OHTB1txfvGC9Hl7PneMnsOG7fuCjiZyStkeagPoePyowcySgYnuXj/M+c6IjiAk0h095oyZuZZB45dx1J3+HWrSs3VVEuKze7ZXJGflxFAbcSecUtp2Bq8VkZD4OOPOVlWZMCCV1tWT+T9f/cjVL8zgew0nLhEoux/yX5vZeDO7w8zuAL4AvgxfLJHodn7xgrx8W2NG3Po/w4n/9dPFmhNbIsqZXKS+FmgV+nWau38UtlRnSaeYJC/67cBhBo1fxhuz1lG2aAH+3vUiOtYtE3QsiRHnPNx3XqGCkLxs3vodPPrBDyz7ZTedLyzLX6++kLLFCgQdS6LcWV+DMLPdZvZbFj+7zey38MQViU2NKpXg8z6t+UPnWkxetoUOg6fyxsy1HDsWPX/ESd5yyoJw9yLuXjSLnyLuXjS3QorEisT4OO5vV51v+relQcXi/PmTxVw74lt+3Ky/xyT36ZtIIhGocqlCvNGzKc/eWJ912/bR5bnp/OfrHzlw+GjQ0SSGqCBEIpSZ0a1hBSYNSOV3DcszbMoqOg1JY/qKX4OOJjFCBSES4UoUyseg6+vzVq9mxJlx6yuz6f/uArbtORh0NIlyKgiRPKJl9dJ81bcND11anc8X/kT7wVN5P32DJieSsFFBiOQhBRLjGXhZLb7o04bqyYX5/biF3PzybFZv3RN0NIlCKgiRPKhmmSK817sFT3W7iEU/7aLz0Gk8P0mTE0nOUkGI5FFxccYtzSozaUAqHeuW4ZkJy7nyuWmkr9XkRJIzVBAiedx5RQvw4s2NePWOFPYdOsp1I2by2Ec/sGu/JieSc6OCEIkSl9Yuwzf929KzdVXe+W49HQZP5fOFP+kitpw1FYRIFCmUP4E/d6nLJw+0pkzR/Dz41nxue/U71vy6N+hokgepIESi0MUVivHx/a144qq6LFi/k07PpjFo/DL2H9Kd2JJ9KgiRKJUQH8edraoyaWAqV9YrxwuTV9Lx2alMWPJL0NEkj1BBiES584oW4NkbG/DOPc1JyhfP3WPS6fnaHNZv05zYcmoqCJEY0bxaKb7o04bHrqjNzNXb6PjsVIZOXKEBAOWkwlYQZvaqmW0xs0UnWV/bzGaa2UEzeziL9fFmNt/MPg9XRpFYkxgfxz1tL2DSwFQ61C3DsxOX02lIGpOXbTn9iyXmhPMI4jWg8ynWbwf6AINOsr4vsDSHM4kIUK5YQV68uRFv9mxGvBl3jp5D7zfS2bRzf9DRJIKErSDcPY2MEjjZ+i3uPgf4X3fzmFkF4EpgVLjyiQi0rlGar/q14fedajF1+VbaPzOFFyev1JAdAkTuNYghwB+A0/5Xamb3mFm6maVv3bo1/MlEokz+hHgeuKQ6EwekklozmafHL6Pz0DRmrNS8E7Eu4grCzLoAW9x9bnae7+4j3T3F3VOSk5PDnE4kelUokcRLPVIYfWcTjh5zbhk1mwfemsfmXQeCjiYBibiCAFoBV5vZWuAd4FIzezPYSCKx45Ja5zG+X1v6dajBhCW/0P6ZKbyctprDR3XaKdZEXEG4+6PuXsHdqwDdgf+6+60BxxKJKQUS4+nXoSYT+6fSrFopnvpyKVc+N41Zq7cFHU1yUTi/5vo2MBOoZWYbzaynmd1rZveG1pc1s43AAODx0HOKhiuPiJy5SqWSeOX2FEb2aMzeg0fpPnIW/d9dwJbdOu0UCyyaRnpMSUnx9PT0oGOIRKX9h47y4uSVjExbTf6EOAZcVpMezSuTEB9xJyLkDJjZXHdPyWqd/s2KSLYUzBfPw51q8XW/NjSoVJy/fbaEq1+Ywdx1mqAoWqkgROSMVEsuzJi7mjLslkZs33uIa4fP5Pfvf8+2PQeDjiY5TAUhImfMzLji4nJMGphK79RqfDR/E5c+M5U3Z63j6LHoOW0d61QQInLWCuVP4NHL6/BV3zbUKVeExz9eRLdhM/h+w86go0kOUEGIyDmrUaYIb9/dnKHdG/DzrgP8btgMHhm3UN92yuNUECKSI8yMrg3K89+BqdzVqiofzt9Iu6en8NykFZrJLo9SQYhIjipSIJE/d6nLhP6ptK2RzOAJy7lk0BTGzd3IMV2fyFNUECISFlVKF2JEj8a817sFZYrm5+H3v+eqF6bz7SoNAphXqCBEJKyaVi3JR/e3YsiNDdix9xA3vzybXq+ns2rrnqCjyWmoIEQk7OLijN81LM9/H27H7zvVYtbqbXR6No0nPlnE9r2Hgo4nJ6GCEJFcUyAxY+6JyQ+348YmFXlj1jpSn57MyLRVHDyiC9mRRgUhIrkuuUh+nup2MV/3a0vjyiX455c/0mHwVD5f+BPRND5cXqeCEJHA1CxThNfubMobPZtSKF8CD741n2uHf8vcdTuCjiaoIEQkArSpkcwXfdrw72svZsOO/Vw7/FsefGseG7bvCzpaTNNw3yISUfYePMJLU1cxctpqjh2DO1tV4f5LqlOsYGLQ0aKShvsWkTyjUP4EBlxWi8kPt+Oq+uczctpq2j09mTEz12ra01ymghCRiFSuWEGeuaE+nz3Ymlpli/CXTxbTaUgaE5f8ogvZuUQFISIR7aLyxXj77ua8fFsKOPQak87NL89m0aZdQUeLeioIEYl4ZkbHumUY378tf7v6Qn7c/BtXvTCdh9//ns27NGJsuOgitYjkObv2H+bFySt5bcZa4uOMu9tWo3fbahTKnxB0tDxHF6lFJKoUK5jIY1fUYdLAVC6tcx7PTVrBJYOm8O6c9ZrRLgepIEQkz6pYMokXb27EB/e1pHyJgjzywQ9c+dw0ZqzUiLE5QQUhInle48ol+PC+ljx/U0P2HDzCLaNm0+v1ORox9hypIEQkKpgZV9U/n4kDUnmkc21mrd5Op2fT+Ouni9mhEWPPigpCRKJKgcR47mt3AZMfbscNTSoyZuZa2g2awivT13DoiG60OxMqCBGJSslF8vPPbhfzZd821KtQjH98voROQ9L4ZvFm3WiXTSoIEYlqtcsWZcxdTRl9RxPiDO55Yy43vzybxT/pRrvTUUGISNQzMy6pfR5f92vL37tm3GjX5fnp/GHc92z5TTfanYwKQkRiRmJ8HLe1qMKUhy+hV+uqfDR/E+0GTeH5SSs4cFgz2p1IBSEiMadYUiJ/urIuE/qn0rZGMs9MWM6lg6bw8fxNHNONdv+PCkJEYlaV0oUY0aMx7yOrvcsAAAoYSURBVNzTnJKF89Hv3QV0G/4tc9dtDzpaRAhbQZjZq2a2xcwWnWR9bTObaWYHzezhTMsrmtlkM1tiZovNrG+4MoqIADSvVopPH2jNoOvrs3nXfq4dPpMHNKNdWI8gXgM6n2L9dqAPMOiE5UeAge5eF2gOPGBmdcOSUEQkJC7OuK5xBSY/3I4+7WswaekvtB88lX9//SO7DxwOOl4gwlYQ7p5GRgmcbP0Wd58DHD5h+c/uPi/0eDewFCgfrpwiIpkl5UtgQMeaTH64HV0uLsfwKato9/QUxs5ex5EYm9Euoq9BmFkVoCEw+xTPucfM0s0sfevWrbkVTUSiXLliBRl8YwM+fbAV1ZIL8aePFnHlc9OZtiJ2PmcitiDMrDDwAdDP3X872fPcfaS7p7h7SnJycu4FFJGYUK9Ccd7r3YLhtzRi3+Ej9HjlO+4c/R0rt+wOOlrYRWRBmFkiGeUw1t0/DDqPiMQ2M+Pyi8sxcUAqj15em/S1O+g0ZBpPfLKI7VE8EGDEFYSZGfAKsNTdBwedR0TkuPwJ8fROvYApv2/HTU0r8sasdbR7ejKjpq2OyoEAwzblqJm9DbQDSgO/AE8AiQDuPsLMygLpQFHgGLAHqAvUA6YBP4SWAzzm7l+e7j015aiI5Kblv+zmqS+WMnX5ViqXSuKJq+pyae0yQcc6I6eaclRzUouInKMpy7bw5BdLWbllD50vLMsTV9elXLGCQcfKFs1JLSISRu1qnceXfdrwh861mLJ8Cx2emcqoaavz/NdiVRAiIjkgX0Ic97erzoT+qTSpWpInv1jK1S/MYP76HUFHO2sqCBGRHFSxZBKj72jC8FsasW3vQa4Z/i2Pf/wDu/bnvbuxVRAiIjks89di72xZlbdmr6f9M1P5ZMGmPDWbnQpCRCRMihRI5C9X1eXTB1tTvngB+r6zgB6vfMeaX/cGHS1bVBAiImF2UflifHh/K/7R9UK+37CTTkPSGDJxecRPUqSCEBHJBfFxRo8WVZg0MJVOF5ZlyMQVXD50GtNX/Bp0tJNSQYiI5KLzihbg+ZsaMuauphxz59ZXZtP3nfls3X0w6Gj/iwpCRCQAbWsmM75fW/q0r8FXP2zm0mem8OasdRE15akKQkQkIAUS4xnQsSZf9WvDxeWL8fjHi7hm+Lcs+emkA1jnKhWEiEjALkguzNhezXj2xvps2L6Pq16YzpOfL2HPwSOB5lJBiIhEADOjW8MK/HdgO25sUpFR09fQcfBUvl60ObB7J1QQIiIRpFhSIv/sdjEf3NeSYgUTuffNufR6PZ2NO/blehYVhIhIBGpcuQSfP9SaP11Rh5mrt9FxcBojpq7icC4OAKiCEBGJUAnxcdzdthoTBqTSpkZp/vXVj3R5bjpz1m7PlfdXQYiIRLjyxQsy8rYUXr4thT0Hj3D9iJk8Mm4hO8I83akKQkQkj+hYtwwTBrSld9tqjJu3kfaDpzJu7sawXcRWQYiI5CFJ+RJ49Io6fNGnNVVLF+Lh97+n+8hZ7DuU81+JTcjxLYqISNjVLluU93u34L30Dcxfv5OkfDn/ca6CEBHJo+LijO5NK9G9aaXwbD8sWxURkTxPBSEiIllSQYiISJZUECIikiUVhIiIZEkFISIiWVJBiIhIllQQIiKSJQtqIopwMLOtwLqzfHlp4NccjJMXaJ+jX6ztL2ifz1Rld0/OakVUFcS5MLN0d08JOkdu0j5Hv1jbX9A+5ySdYhIRkSypIEREJEsqiP8xMugAAdA+R79Y21/QPucYXYMQEZEs6QhCRESypIIQEZEsxXxBmFlnM1tmZivN7I9B5wk3M6toZpPNbImZLTazvkFnyi1mFm9m883s86Cz5AYzK25m48zsRzNbamYtgs4UbmbWP/Tf9SIze9vMCgSdKaeZ2atmtsXMFmVaVtLMJpjZitA/S+TEe8V0QZhZPPAicDlQF7jJzOoGmyrsjgAD3b0u0Bx4IAb2+bi+wNKgQ+SiocDX7l4bqE+U77uZlQf6ACnufhEQD3QPNlVYvAZ0PmHZH4FJ7l4DmBT6/ZzFdEEATYGV7r7a3Q8B7wBdA84UVu7+s7vPCz3eTcaHRvlgU4WfmVUArgRGBZ0lN5hZMaAt8AqAux9y953BpsoVCUBBM0sAkoCfAs6T49w9Ddh+wuKuwOuhx68Dv8uJ94r1gigPbMj0+0Zi4MPyODOrAjQEZgebJFcMAf4AHAs6SC6pCmwFRodOq40ys0JBhwond98EDALWAz8Du9z9m2BT5Zoy7v5z6PFmoExObDTWCyJmmVlh4AOgn7v/FnSecDKzLsAWd58bdJZclAA0Aoa7e0NgLzl02iFShc67dyWjHM8HCpnZrcGmyn2ece9Cjty/EOsFsQmomOn3CqFlUc3MEskoh7Hu/mHQeXJBK+BqM1tLxmnES83szWAjhd1GYKO7Hz86HEdGYUSzDsAad9/q7oeBD4GWAWfKLb+YWTmA0D+35MRGY70g5gA1zKyqmeUj44LWpwFnCiszMzLOSy9198FB58kN7v6ou1dw9ypk/Dv+r7tH9V+W7r4Z2GBmtUKL2gNLAoyUG9YDzc0sKfTfeXui/MJ8Jp8Ct4ce3w58khMbTciJjeRV7n7EzB4ExpPxjYdX3X1xwLHCrRXQA/jBzBaElj3m7l8GmEnC4yFgbOiPn9XAnQHnCSt3n21m44B5ZHxbbz5ROOyGmb0NtANKm9lG4AngX8B7ZtaTjCkPbsiR99JQGyIikpVYP8UkIiInoYIQEZEsqSBERCRLKggREcmSCkJERLKkghAJkJm1i5XRZSXvUUGIiEiWVBAi2WBmt5rZd2a2wMxeCs0tscfMng3NPzDJzJJDz21gZrPMbKGZfXR8bH4zq25mE83sezObZ2YXhDZfONO8DWNDdwFjZv8Kzdux0MwGBbTrEsNUECKnYWZ1gBuBVu7eADgK3AIUAtLd/UJgKhl3tAKMAR5x93rAD5mWjwVedPf6ZIwRdHz0zYZAPzLmJKkGtDKzUkA34MLQdp4M716K/G8qCJHTaw80BuaEhidpT8YH+THg3dBz3gRah+ZhKO7uU0PLXwfamlkRoLy7fwTg7gfcfV/oOd+5+0Z3PwYsAKoAu4ADwCtmdg1w/LkiuUYFIXJ6Brzu7g1CP7Xc/a9ZPO9sx605mOnxUSDB3Y+QMaHVOKAL8PVZblvkrKkgRE5vEnCdmZ0H/2/+38pk/P9zXeg5NwPT3X0XsMPM2oSW9wCmhmbv22hmvwttI7+ZJZ3sDUPzdRQLDaLYn4wpQ0VyVUyP5iqSHe6+xMweB74xszjgMPAAGZPwNA2t20LGdQrIGG55RKgAMo+i2gN4ycz+HtrG9ad42yLAJ2ZWgIwjmAE5vFsip6XRXEXOkpntcffCQecQCRedYhIRkSzpCEJERLKkIwgREcmSCkJERLKkghARkSypIEREJEsqCBERydL/BSmQ+0awUqysAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bFZ-p5Daeluq",
        "outputId": "8393eeb2-9773-451e-8625-63e99a1e9496"
      },
      "source": [
        "plt.plot(epochs[75:], losses[75:])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel('losses')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njgpTYaf_frh"
      },
      "source": [
        "preds=baseline_model().predict_classes(X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWowULTbsMHj",
        "outputId": "d36976df-f237-4114-864f-f80337c86c04"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(dummy_y, preds,normalize='true')\n",
        "print(conf_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.   1.  ]\n",
            " [0.32 0.   0.68]\n",
            " [1.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgWw9tfKSYNO"
      },
      "source": [
        "**Benchmark:** \n",
        "\n",
        "Accuracy avant :0.7200000166893006\n",
        "\n",
        "1/checkpoint: 0.7000000178813934\n",
        "\n",
        "2/early_stopping : 0.7066666811704636\n",
        "\n",
        "3/checkpoint +early_stopping: 0.6733333528041839\n",
        "\n",
        "4/rgularisation :0.9066666722297668\n",
        "\n",
        "5/checkpoint+early_stopping+rgularisation :0.9333333373069763\n",
        "\n",
        "6/checkpoint+early_stopping+rgularisation+reduce_lr: 0.9600000023841858\n",
        "\n",
        "7/rgularisation+reduce_lr: 0.9333333373069763"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac5p22wQpX0p"
      },
      "source": [
        "Le meilleur rsultat obtenu est **0.9600000023841858**\n",
        "les techniques utilises :\n",
        "\n",
        "1/checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor=\"accuracy\")\n",
        "\n",
        "2/early_stopping = EarlyStopping(monitor=\"accuracy\", patience=16, min_delta=10000)\n",
        "\n",
        "3/reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=10, min_delta=100000)\n",
        "\n",
        "4/model.add(Dense(8, input_dim=4, activation='relu', kernel_regularizer='l1', bias_regularizer='l2', activity_regularizer='l1_l2'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOtOeZF6EVDI"
      },
      "source": [
        "**Refaire le TP avec Keras Tuner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADwB2o-4EgQE"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import IPython"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Iv7DW9EjWA",
        "outputId": "2e01fd2f-e141-41b5-c1c8-0e6fd8608cff"
      },
      "source": [
        "!pip install -U keras-tuner\r\n",
        "import kerastuner as kt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |                          | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |                     | 20kB 12.4MB/s eta 0:00:01\r\u001b[K     |                | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |           | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |      | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     || 61kB 5.1MB/s eta 0:00:01\r\u001b[K     || 71kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.7)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=27f54fda383ebc318b2a4bf2908358ee0fcdbc08c883de483b434c64e8e557d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15357 sha256=06381e613af2d7e70c7950ae24d5e96067fb4ad3c9e15c8cd260406fd4d54563\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ELDZq02E7c6"
      },
      "source": [
        "def model_builder(hp):\r\n",
        "  model = keras.Sequential()\r\n",
        "  \r\n",
        "  # Tune the number of units in the first Dense layer\r\n",
        "  # Choose an optimal value between 32-512\r\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\r\n",
        "  model.add(keras.layers.Dense(units = hp_units, activation = 'softmax'))\r\n",
        "  model.add(keras.layers.Dense(10))\r\n",
        "\r\n",
        "  # Tune the learning rate for the optimizer \r\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\r\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \r\n",
        "  \r\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\r\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \r\n",
        "                metrics = ['accuracy'])\r\n",
        "  \r\n",
        "  return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CFQy5m1HIbl",
        "outputId": "6b7d70b8-4181-4efb-f39f-8cab0fa98063"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\r\n",
        "                     objective = 'accuracy', \r\n",
        "                     max_epochs = 10,\r\n",
        "                     factor = 3,\r\n",
        "                     directory = 'my_dir',\r\n",
        "                     project_name = 'intro_to_kt')   "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F6CFEFRHWFa"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\r\n",
        "  def on_train_end(*args, **kwargs):\r\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg424S_uK9uj"
      },
      "source": [
        "X = X.reshape(1,-1)\r\n",
        "dummy_y = dummy_y.reshape(1,-1)\r\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09hO7gHxHa81",
        "outputId": "4ce73829-4b12-42a3-8bdc-a0063799d736"
      },
      "source": [
        "tuner.search(X, dummy_y, epochs = 10, callbacks = [ClearTrainingOutput()])\r\n",
        "\r\n",
        "# Get the optimal hyperparameters\r\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\r\n",
        "\r\n",
        "print(f\"\"\"\r\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\r\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\r\n",
        "is {best_hps.get('learning_rate')}.\r\n",
        "\"\"\")\r\n",
        "\r\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 00s]\n",
            "accuracy: 0.0\n",
            "\n",
            "Best accuracy So Far: 1.0\n",
            "Total elapsed time: 00h 00m 14s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 160 and the optimal learning rate for the optimizer\n",
            "is 0.01.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvJDWp40KIY8",
        "outputId": "1540a8aa-44de-48d6-80fc-4f062067347a"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data\r\n",
        "model = tuner.hypermodel.build(best_hps)\r\n",
        "model.fit(X, dummy_y, epochs = 10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2844 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 940us/step - loss: 2.1961 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1370 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0896 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0430 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9957 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9494 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9031 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8610 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8220 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6be686c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}